{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "review json is 5.2 GB uncompressed with 6685900 lines corresponding to reviews and review metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_chunks = pd.read_json('../data/yelp_dataset/review.json', lines=True, chunksize=400000)\n",
    "\n",
    "# chunks = []\n",
    "\n",
    "# for chunk in df_chunks:\n",
    "#     chunks.append(chunk[(chunk.stars == 5.0) & (chunk.useful > 0)])\n",
    "\n",
    "# df_useful = pd.concat(chunks)\n",
    "\n",
    "# df_useful.to_csv('../data/useful_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\K\\Miniconda3\\envs\\tf-gpu-cuda10\\lib\\site-packages\\numpy\\lib\\arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/useful_reviews.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3733\n",
      "5445501\n",
      "Wall time: 281 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n = 30\n",
    "print(df[df.useful >= n].shape[0])\n",
    "print(len(df[df.useful >= n].text.str.cat(sep='\\n')))\n",
    "text = df[df.useful >= n].text.str.cat(sep='\\n')\n",
    "df = df[df.useful >= n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1194239 reviews have been voted useful.  \n",
    "591242 reviews have more than 1 useful vote.  \n",
    "335812 reviews have more than 2 useful votes.  \n",
    "211232 reviews have more than 3 useful votes.  \n",
    "31020 reviews have more than 10 useful votes.  \n",
    "1812 reviews have 40+ useful votes.*  \n",
    "*For reduced computation time during this prototyping phase, I will use this reduced data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_length = df.text.str.len()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descriptive statistics of length of reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3733.000000\n",
       "mean     1457.746852\n",
       "std      1047.341406\n",
       "min        56.000000\n",
       "25%       683.000000\n",
       "50%      1217.000000\n",
       "75%      1962.000000\n",
       "max      5000.000000\n",
       "Name: text, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_length.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1b192893308>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_length.plot(kind='hist', bins='fd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145 unique characters\n"
     ]
    }
   ],
   "source": [
    "# The unique characters in the file\n",
    "vocab = sorted(set(text))\n",
    "print ('{} unique characters'.format(len(vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a mapping from unique characters to indices\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_as_int = np.array([char2idx[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The maximum length sentence we want for a single input in characters\n",
    "seq_length = 100\n",
    "examples_per_epoch = len(text)//(seq_length+1)\n",
    "\n",
    "# Create training examples / targets\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T\n",
      "h\n",
      "i\n",
      "s\n",
      " \n"
     ]
    }
   ],
   "source": [
    "for i in char_dataset.take(5):\n",
    "  print(idx2char[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"This is my favorite park in Vegas! \\n\\n2016 Yelp 100 Review Challenge -     12/100\\n\\n\\nI've heard about t\"\n",
      "\"his park from family and friends over the years, but didn't experience it myself till sometime last y\"\n",
      "'ear. After that, I began coming here for my morning cardio (walk/run/hike) several days a week. \\n\\nI a'\n",
      "'gree with many of the reviews for this park. It has a little bit of everything and more. \\n\\n- A bad as'\n",
      "'s playground I wish existed during my childhood. \\n\\n- A huge grassy area for picnics, soccer, and just'\n"
     ]
    }
   ],
   "source": [
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "for item in sequences.take(5):\n",
    "  print(repr(''.join(idx2char[item.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  \"This is my favorite park in Vegas! \\n\\n2016 Yelp 100 Review Challenge -     12/100\\n\\n\\nI've heard about \"\n",
      "Target data: \"his is my favorite park in Vegas! \\n\\n2016 Yelp 100 Review Challenge -     12/100\\n\\n\\nI've heard about t\"\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in  dataset.take(1):\n",
    "  print ('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
    "  print ('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step    0\n",
      "  input: 51 ('T')\n",
      "  expected output: 71 ('h')\n",
      "Step    1\n",
      "  input: 71 ('h')\n",
      "  expected output: 72 ('i')\n",
      "Step    2\n",
      "  input: 72 ('i')\n",
      "  expected output: 82 ('s')\n",
      "Step    3\n",
      "  input: 82 ('s')\n",
      "  expected output: 1 (' ')\n",
      "Step    4\n",
      "  input: 1 (' ')\n",
      "  expected output: 72 ('i')\n"
     ]
    }
   ],
   "source": [
    "for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n",
    "    print(\"Step {:4d}\".format(i))\n",
    "    print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
    "    print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "  model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                              batch_input_shape=[batch_size, None]),\n",
    "    tf.keras.layers.GRU(rnn_units,\n",
    "                        return_sequences=True,\n",
    "                        stateful=True,\n",
    "                        recurrent_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dense(vocab_size)\n",
    "  ])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "  vocab_size = len(vocab),\n",
    "  embedding_dim=embedding_dim,\n",
    "  rnn_units=rnn_units,\n",
    "  batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 145) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "  example_batch_predictions = model(input_example_batch)\n",
    "  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (64, None, 256)           37120     \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (64, None, 1024)          3938304   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (64, None, 145)           148625    \n",
      "=================================================================\n",
      "Total params: 4,124,049\n",
      "Trainable params: 4,124,049\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 78, 141,  40,  35, 119,  71,  92, 138, 107,  88, 136, 118,  52,\n",
       "       110, 116,  41,  35,  83, 132, 100,  40,  51,  19,  87,  40, 106,\n",
       "         7, 142,  42, 109,  84,  35,   7,  85,  79,  45,  30,  93, 144,\n",
       "        78,  55,  15,  97, 142,  68, 122,  30,   5,  85, 140,  55,  43,\n",
       "        29,  85,  89,  19,  42, 107,  36,  48, 117, 105,  98,  28,  96,\n",
       "       124,   1,   4,  57,  25,  32,  33,   9,  13,  80,  55, 109, 110,\n",
       "        80,  15, 105,  12,  80, 120,  13,  38,  24,  32,  64,  46,  78,\n",
       "        43,  42,  42, 117,   6,  52,  50,  59,   9], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      " 's!\\n...food os alsome here..this place is a gem ... I will be back ... great deals... killer wicked t'\n",
      "\n",
      "Next Char Predictions: \n",
      " 'o菊IDíh}梅ÜyすëUáéJDt―ÂIT2xIÛ&蘭KàuD&vpN?~頂oX.´蘭eñ?$v竹XL=vz2KÜEQêÓº;²ô #Z8AB(,qXàáq.Ó+qî,G7AaOoLKKê%US\\\\('\n"
     ]
    }
   ],
   "source": [
    "print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
    "print()\n",
    "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices ])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 100, 145)  # (batch_size, sequence_length, vocab_size)\n",
      "scalar_loss:       4.978125\n"
     ]
    }
   ],
   "source": [
    "def loss(labels, logits):\n",
    "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "example_batch_loss  = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 842 steps\n",
      "Epoch 1/30\n",
      "842/842 [==============================] - 856s 1s/step - loss: 1.9921\n",
      "Epoch 2/30\n",
      "842/842 [==============================] - 858s 1s/step - loss: 1.4514\n",
      "Epoch 3/30\n",
      "842/842 [==============================] - 860s 1s/step - loss: 1.3572\n",
      "Epoch 4/30\n",
      "842/842 [==============================] - 836s 993ms/step - loss: 1.3080\n",
      "Epoch 5/30\n",
      "842/842 [==============================] - 831s 987ms/step - loss: 1.2742\n",
      "Epoch 6/30\n",
      "842/842 [==============================] - 837s 994ms/step - loss: 1.2484\n",
      "Epoch 7/30\n",
      "842/842 [==============================] - 830s 986ms/step - loss: 1.2276\n",
      "Epoch 8/30\n",
      "842/842 [==============================] - 831s 987ms/step - loss: 1.2109\n",
      "Epoch 9/30\n",
      "842/842 [==============================] - 831s 986ms/step - loss: 1.1973\n",
      "Epoch 10/30\n",
      "842/842 [==============================] - 825s 980ms/step - loss: 1.1865\n",
      "Epoch 11/30\n",
      "842/842 [==============================] - 822s 976ms/step - loss: 1.1778\n",
      "Epoch 12/30\n",
      "842/842 [==============================] - 820s 974ms/step - loss: 1.1712\n",
      "Epoch 13/30\n",
      "842/842 [==============================] - 817s 970ms/step - loss: 1.1671\n",
      "Epoch 14/30\n",
      "842/842 [==============================] - 816s 969ms/step - loss: 1.1644\n",
      "Epoch 15/30\n",
      "842/842 [==============================] - 808s 960ms/step - loss: 1.1634\n",
      "Epoch 16/30\n",
      "842/842 [==============================] - 818s 971ms/step - loss: 1.1635\n",
      "Epoch 17/30\n",
      "842/842 [==============================] - 808s 959ms/step - loss: 1.1659\n",
      "Epoch 18/30\n",
      "842/842 [==============================] - 810s 962ms/step - loss: 1.1708\n",
      "Epoch 19/30\n",
      "842/842 [==============================] - 813s 965ms/step - loss: 1.1781\n",
      "Epoch 20/30\n",
      "842/842 [==============================] - 809s 961ms/step - loss: 1.1855\n",
      "Epoch 21/30\n",
      "842/842 [==============================] - 807s 959ms/step - loss: 1.2153\n",
      "Epoch 22/30\n",
      "842/842 [==============================] - 807s 959ms/step - loss: 1.2153\n",
      "Epoch 23/30\n",
      "842/842 [==============================] - 808s 959ms/step - loss: 1.2193\n",
      "Epoch 24/30\n",
      "842/842 [==============================] - 806s 957ms/step - loss: 1.2577\n",
      "Epoch 25/30\n",
      "842/842 [==============================] - 814s 967ms/step - loss: 1.4293\n",
      "Epoch 26/30\n",
      "842/842 [==============================] - 803s 954ms/step - loss: 1.5127\n",
      "Epoch 27/30\n",
      "842/842 [==============================] - 804s 955ms/step - loss: 2.0795\n",
      "Epoch 28/30\n",
      "842/842 [==============================] - 802s 952ms/step - loss: 2.0716\n",
      "Epoch 29/30\n",
      "842/842 [==============================] - 801s 951ms/step - loss: 2.0330\n",
      "Epoch 30/30\n",
      "842/842 [==============================] - 794s 943ms/step - loss: 2.0158\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.train.latest_checkpoint(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (1, None, 256)            31232     \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (1, None, 1024)           3938304   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (1, None, 122)            125050    \n",
      "=================================================================\n",
      "Total params: 4,094,586\n",
      "Trainable params: 4,094,586\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string):\n",
    "  # Evaluation step (generating text using the learned model)\n",
    "\n",
    "  # Number of characters to generate\n",
    "  num_generate = 1000\n",
    "\n",
    "  # Converting our start string to numbers (vectorizing)\n",
    "  input_eval = [char2idx[s] for s in start_string]\n",
    "  input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "  # Empty string to store our results\n",
    "  text_generated = []\n",
    "\n",
    "  # Low temperatures results in more predictable text.\n",
    "  # Higher temperatures results in more surprising text.\n",
    "  # Experiment to find the best setting.\n",
    "  temperature = 1.0\n",
    "\n",
    "  # Here batch size == 1\n",
    "  model.reset_states()\n",
    "  for i in range(num_generate):\n",
    "      predictions = model(input_eval)\n",
    "      # remove the batch dimension\n",
    "      predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "      # using a categorical distribution to predict the character returned by the model\n",
    "      predictions = predictions / temperature\n",
    "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "      # We pass the predicted character as the next input to the model\n",
    "      # along with the previous hidden state\n",
    "      input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "      text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "  return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMEO: ESPñary!!G!\n",
      "Wbay M$G un bel Lost and coor ackian me with furas afwer all the pursuate Wapmerin. : X7 make comething as nextrischould lefforment to bit! Whey are penfectiver rithle whot truseds:!, but 15 meas  with that'r moke abazing tolk waith by fromblat on and comervictly new a was tho great firnating spot out bank timul of be ands. If yod being the, playes on the cous of went definitely midred butttew. When I'm Onigrifulinally.. Ay! \n",
      "\n",
      "They caped!\n",
      "\n",
      "My no reme goodint or $6.  keart musally serviped bricks you wir like a some whene tixe to fenticially love servels, I nentidely, rellind bs for of Rapar Peiticel)\n",
      "ToonGreakis alo/C!!N! \n",
      "\n",
      "*Hen a lott dine of Dood, Nommy and Freatonful surmy. The Manchas:  A list ands the madaded to took dinn's ipporter, wordswish spullers. If youp of supming berbinire my over of it's a  Orrenche- Mise! Wit I dinesthe with samisal I ondo, the reastas adous neverve beet, the I cherouth that in't be achout thanksard to to toughtyulk dilicee bus, betwoul? it'\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, start_string=u\"ROMEO: \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "  vocab_size = len(vocab),\n",
    "  embedding_dim=embedding_dim,\n",
    "  rnn_units=rnn_units,\n",
    "  batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, target):\n",
    "  with tf.GradientTape() as tape:\n",
    "    predictions = model(inp)\n",
    "    loss = tf.reduce_mean(\n",
    "        tf.keras.losses.sparse_categorical_crossentropy(\n",
    "            target, predictions, from_logits=True))\n",
    "  grads = tape.gradient(loss, model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 4.803240776062012\n",
      "Epoch 1 Batch 100 Loss 2.494201421737671\n",
      "Epoch 1 Loss 2.3779\n",
      "Time taken for 1 epoch 114.38218069076538 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 2.341761827468872\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-edc7e3ec95ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbatch_n\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbatch_n\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m100\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\tf-gpu-cuda10\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\tf-gpu-cuda10\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\tf-gpu-cuda10\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\tf-gpu-cuda10\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\tf-gpu-cuda10\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\tf-gpu-cuda10\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\tf-gpu-cuda10\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training step\n",
    "EPOCHS = 2\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "\n",
    "  # initializing the hidden state at the start of every epoch\n",
    "  # initally hidden is None\n",
    "  hidden = model.reset_states()\n",
    "\n",
    "  for (batch_n, (inp, target)) in enumerate(dataset):\n",
    "    loss = train_step(inp, target)\n",
    "\n",
    "    if batch_n % 100 == 0:\n",
    "      template = 'Epoch {} Batch {} Loss {}'\n",
    "      print(template.format(epoch+1, batch_n, loss))\n",
    "\n",
    "  # saving (checkpoint) the model every 5 epochs\n",
    "  if (epoch + 1) % 5 == 0:\n",
    "    model.save_weights(checkpoint_prefix.format(epoch=epoch))\n",
    "\n",
    "  print ('Epoch {} Loss {:.4f}'.format(epoch+1, loss))\n",
    "  print ('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n",
    "\n",
    "model.save_weights(checkpoint_prefix.format(epoch=epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
