{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models with Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# for data processing for Tensorflow\n",
    "import numpy as np\n",
    "# for saving Tensorflow checkpoints\n",
    "import os\n",
    "# for loading and manipulating data\n",
    "import pandas as pd\n",
    "# for neural networks\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "review.json is 5.2 GB uncompressed with 6685900 lines corresponding to reviews and review metadata.  \n",
    "It is too large to load completely into memory so I will load pieces of it as needed (pandas chunksize argument.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time #4min 38s\n",
    "# # load data using chunksize option\n",
    "# df_chunks = pd.read_json('../data/yelp_dataset/review.json', lines=True, chunksize=400000)\n",
    "\n",
    "# # list to hold chunks after querying\n",
    "# chunks = [chunk[(chunk.stars == 5.0) & (chunk.useful > 0)] for chunk in df_chunks]\n",
    "\n",
    "# # dataframe of useful 5-star reviews\n",
    "# df = pd.concat(chunks)\n",
    "\n",
    "# # save csv for faster loading in the future\n",
    "# df.to_csv('../data/useful_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\K\\Miniconda3\\envs\\tf-gpu-cuda10\\lib\\site-packages\\numpy\\lib\\arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# load data from csv for a faster start\n",
    "df = pd.read_csv('../data/useful_reviews.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add <SOR> and <EOR> tokens to delimit reviews\n",
    "df.text = df.text.apply(lambda x: '<SOR>' + x + '<EOR>')\n",
    "df_copy = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5696\n",
      "7970555\n"
     ]
    }
   ],
   "source": [
    "# minimum number of useful votes to include\n",
    "n = 25\n",
    "\n",
    "# number of reviews in subset\n",
    "print(df_copy[df_copy.useful >= n].shape[0])\n",
    "\n",
    "# number of characters in subset\n",
    "print(len(df_copy[df_copy.useful >= n].text.str.cat()))\n",
    "\n",
    "# block of text to serve as model training data\n",
    "text = df_copy[df_copy.useful >= n].text.str.cat()\n",
    "\n",
    "# dataframe to allow for eda plots\n",
    "df = df_copy[df_copy.useful >= n]\n",
    "\n",
    "# subset for eda plotting about comment characteristics\n",
    "text_length = df.text.str.len()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1194239 reviews have been voted useful.  \n",
    "591242 reviews have more than 1 useful vote.  \n",
    "335812 reviews have more than 2 useful votes.  \n",
    "211232 reviews have more than 3 useful votes.  \n",
    "31020 reviews have more than 10 useful votes.  \n",
    "5696 reviews have 25+ useful votes.*  \n",
    "3733 reviews have 30+ useful votes.  \n",
    "1812 reviews have 40+ useful votes.  \n",
    "*For reduced computation time during this prototyping phase, I will use this reduced data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments with at least 30 useful votes have a mean length of 1458 characters.  \n",
    "Comments with at least 25 useful votes have a mean length of 1399 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5696.000000\n",
       "mean     1399.324965\n",
       "std      1011.935319\n",
       "min        66.000000\n",
       "25%       648.750000\n",
       "50%      1160.500000\n",
       "75%      1869.250000\n",
       "max      5010.000000\n",
       "Name: text, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_length.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['<SOR>I received the product as expected and on time.  Thanks!<EOR>'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text[text_length == 66].values # shortest review. user and business id are hashed and requiring merging a different json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['<SOR>The ratings are not a lie and I have a new Top 3 favourite spot in Toronto. There\\'s a lot of great things about Richmond Station.. but if there is one takeaway from my review, let it be this.  If you want a phenomenal meal, ask specifically for the chef pass and the chef tasting menu.  Not only is it a feast for your taste buds and eyes... it is a feast of all senses.  \\n\\nFrom the outside, you wouldnt think automatically a restaurant of this calibre and space would be hiding behind a simple window golden font of Richmond Station and a tiny signage with  simple words of \\'Restaurant\\'.  If you peered in, you\\'d see an overflowing amount of people enjoying a lot of interesting dishes.  You\\'ll also notice a lot of people coming in to only be sadly turned away.  \\n\\nThe space is warm and welcoming... there\\'s no pretentious airs here.  It\\'s quite different from my other 2 favourite higher end spots (Buca and Grey Gardens).  The atmosphere here is relaxed and if anything, more casual ... though do not mistaken this for a bar atmosphere.  It\\'s still refined with its wood accents and clean lines but the staff creates more of an approachable vibe.  You can see the humour in the hallway to the bathrooms where they have snapshots and commentary of the restaurant.  One of the chefs has a Calgary Flames hat ... the snap of him has \"Get him a leafs hat\".  I will say the tables are kinda close... we heard other table\\'s conversation more than a few times.  \\n\\nBefore I go into the food... I do have to say that Richmond station is possibly my 3rd favourite only because of the kitchen pacing.  For us, our first two dishes were the oysters and charcuterie.  Though they were good... it was 50 minutes after being seated that we got our charcuterie.  If the pacing was better, this would have been my top favourite. \\n\\nWith the chef menu at $65, it does seem a bit pricey but let me tell you that you will feast and be blown away by what you\\'re given.  We were offered a total of 7 dishes with a final offering of petit four ... so 8 dishes really.  So if you\\'re concerned you will be not getting any value... put those fears aside & just enjoy the show.\\n\\nChef Menu \\n\\nOysters on the half shell - Briney & bright with minimal metallic flavour ... the addition of the horseradish & lemons makes this starter pop.  The oysters were a generous size (not too big) and perfectly opened... not a speck of shell or sand.  You\\'re treated to 2 oysters each.  4.5/5\\n\\nIn house made Charcuterie - If someone says no to this beauty of a platter, I dont think we can be friends.  With 5 types of offerings & a side of pickled vegetables & bold savoury mustards, this was just a great way to perk my taste buds more.  The pickled beats was a perfect pairing to the fatty rich meat.  I wish I could have had more.  The bacalhau (spelling... salted cod really) was just so tender after breaking through the greaseless crispy shell.   5/5\\n\\nBrassica Caesar - This is an interesting take on a Caesar salad.  Instead of the mayo bland romaine lettuce, they used broccoli, cauliflower, shredded cabbage, roasted sprouts, with a health dose of roasted nuts (love their crunch and smokiness), parmigana, and yes... anchovies.  BUT these anchovies are tender savoury bursts ... it\\'s good.  Trust the chef.  I love the take on this classic.  4.5/5\\n\\nRoasted Cod - OH YES... definitely a perfectly cooked and seared fish.  The perfect crispy sear gave way to a tender white fish.  Seasoned so well...it still tasted of sweet fresh fish.  I liked this a lot but what was also great was the bold pairing of the red pepper rouille that sat on top of the sourdough bread.  I think I lost my piece of red pepper bread to a hungrier cub cause it was that good. 5/5\\n\\nSirloin - I learned they dry age these in house... up to 6 weeks and you can honestly taste the nuances.  This was very savoury with the perfect sear.  It\\'s just so ... meaty and beefy in flavour but so tender in texture.  I wouldnt say it\\'s spongey soft like a tenderloin but this might be one of the better sirloins I\\'ve eaten.  The bloodthirsty carnivore in me loved every bite.  5/5\\n\\nStation Burger - Oh hell yes... It has been more than 4 years since I\\'ve eaten a burger and wow, what a bite to break that up.  Damn.  Ok, I get why this has been on the menu since the start.  It\\'s cooked to a juicy medium rare and served with a lot of great flavours.  You have the soft milk bun ready to sop up all the juices, bold acidity of the beet chutney and pickles that cut through the beef, the mild sweetness of beets, aged cheddar for a bite, and aioli for the lucious texture. 5/5\\n\\nCreamsicle - Deconstructured with many components.  It\\'s more subtle orange flavours paired with licorice flavoured fennel and graham.  Orange white chocolate mousse, grand marnier creme, fennel sherbert, and graham cracker soil is all great when put on one spoon.  4.5/5\\n\\nPetit Four - Dense dark fudge, bright & tart cranberry gelee, earl grey macaron, meringue.  Nice presentation. 4/5<EOR>',\n",
       "       \"<SOR>REVIEW # 10\\n\\nI found out about Pink Jeep as I was researching tours for the Grand Canyon. The Grand Canyon was the first thing on my to-do list once I went to Arizona. I knew nothing about the Grand Canyon other than its huge, has beautiful views and a tour guide is the best choice if you want to get the most of your view and days' worth.\\nTwo months before I booked with Pink Jeep. I was back and forth with this company and many other jeep tour companies but after speaking to Margie, a wonderful woman with tons of patience she went over everything that the tour offered and the breakdown of the day. \\nI went ahead and booked the tour which was $135 with taxed turned out to be $170. The price included a 13 hour tour. Pick up at 6:30AM with a drop off at around 8 or 9PM. Here are the details about the tour:\\n\\nPICK UP TIME:\\nPick up time was smooth. I had the pleasure of being picked up by a nice gentleman named Dan. I knew exactly that it was my car when they pulled up because of the big bus which was totally noticeable from a mile away. Once we got in Dan notified me that it would be only 1 more passenger that day so it was a small group and I am SO happy it was, it made the experience THAT much better! We picked up the next young lady traveler and then we were on our way to Sedona!\\n\\nTHE DRIVE:\\nWas smooth! Dan spoke to me and the young lady the whole way giving us history on what we were looking at/the views as well as the history of Arizona itself! It was amazing! On the ride, I also learned that the cactuses that are in Arizona are about 100-200 years old and you can get a fine for hurting them! Can you believe that? Well believe it, because my tour guide Dan told me that and that man was so dang knowledgeable! I could hear him talk all day and wouldn't get tired!\\n\\nTHE BUS:\\nWas fancy! I mean FANCY! The seats are really comfortable and sit a great amount of passengers. The seats recline so you can move it to fit your preference. I was so happy I was able to charge my phone on the bus as the bus is equipped with plugs! Big A+! There is AC on the bus and they also provide snacks and drinks so in case you forget no worries! Pink Jeeps has you covered!\\n\\nMY TOUR GUIDE:\\nMy tour guide was absolutely phenomenal! Dan the man totally exceeded my expectations! From the time he picked me up to the time he dropped me off I was totally impressed with his Hospitality and customer service. When we made our way to Sedona I was in awe with the views and Dan was even nice enough to be my photographer for the whole day! After Sedona we got back in the bus and took a nice drive to the headquarters of Pink Jeep and spent a couple hours exploring that area and picking up our lunches, taking a lunch break and doing some shopping.  \\nTHE SOUTH RIM GRAND CANYON:\\nOkay, so let me be honest and say this was my BEST part of my trip! I had a great time and I give all the praise to Dan! Once we made it to the Grand Canyon Dan gave me the run down on where to start and where he would pick me up! Let me tell you that the Grand Canyon is HUGEE!! Dan gave us about 2-3 hours to explore the canyon on our own and gave us his number so we could call him if we needed him for anything! I started at the beginning point and took TONS of pictures!! I seemed to walk about 2miles and seen views that are indescribable; I mean pictures are not even good enough to explain! I ran into great people from all different types of the world and even seen some performances which were amazing! As I walked around I took amazing pictures of me by the rim and as I thought I reached the end I called Dan to come pick me up and once he told me that I still had an hour to go I felt like a whole day at the Grand Canyon was not enough at all!\\nDan came and picked me up where I was standing and took me around to meet our other young lady that took the tour with us. We got out the bus and Dan gave both of us so incredible tours of the canyon and really had us come out of our comfort zone! I am nerves of heights and Dan was able to have me trust him (just a little bit) so I could take incredible pictures of me sitting on the rim of Grand Canyon! If you are given the chance to step out of your comfort zone please take the risk because you will not regret it! The views are amazing and the pictures that Dan took of me had people thinking I was climbing the Grand Canyon! It was so cool!! I wish there was an option to spend a night with the Pink Jeep and wake up and tour more of the canyon!\\nOverall, I can take pictures and have you seen how amazing the Grand Canyon is but the pictures will not do any justice! You have to go visit this place as well as take Pink Jeep tour to make sure you get the big buck for your money! I was thinking about doing this tour without a guide and I personally do not think I would have been able to see everything that I did if I was to do it solo. Pink Jeep tours totally exceeded my expectations and I thank Dan for being the amazing tour guide! \\nREVIEW 133/196<EOR>\"],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text[text_length == 5010].values # longest reviews. user and business id are hashed and requiring merging a different json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3de5xcRZ338c+XGAn3EDJgSEICSxTQFwYMl2fxEgFBAhLcBcEbyLJGVljlEZWAruKFfcBFYXlQMAgaEIUAChFQCXddhTBIEhMCMoRAhkQyXEIIlwDht39UNfQMnUwnmTN9Zvr7fr361edUn0ud6pn+ddWprlJEYGZmVjYbNDoDZmZmtThAmZlZKTlAmZlZKTlAmZlZKTlAmZlZKTlAmZlZKTlAWUMo+amkZyTNrGP7n0n6bm/krct5L5T0H7193npI+oykPzY6H2ZFcYCyNZIUknbskna6pJ+v56HfC3wIGBERe67PgfIH9SpJKyQtlzRb0iHrmT8AIuL4iPhOTxxrXUg6UNKdkp6T1CHpDkmHNio/tUgaL6m9gONuLulcSY/l97Ytrw/t6XN1Oa8Df0k4QFmjjAIWRsTzPXS8P0fEpsBg4EfAFZIG99CxG0LS4cBVwKXACGAb4BvARwo411t6+pjrc25JbwVuAd4JfBjYHPhH4Clgvb7QWN/hAGXrRdJQSddLWibpaUl/kLRBfm1bSdfkb/6PSPpCTj8O+Anwf/I342/V+tZaq/bWnYh4DbgM2AQYU3WsvSX9KedztqTxOf0oSa1dzvt/JU3Py52aFiUdImlWPs6fJO2a04+V9Juq7dokTataXyRpbG7aPEfSUknPSpoj6V01ylXAD4DvRMRPIuLZiHgtIu6IiM922fbs3FT6iKSDqtKPlTQ/174WSPpc1WvjJbVLOkXS34GfStoyv5cd+XjXSxpRtc+Q3Cy7OL9+raRNgN8C2+b3ckV+3zeQNFnSw5KekjRN0pB8nNH5vT1O0mPArTXeyqOB7YCPRsT9+dqXRsR3IuLGfJydJd2e34t51TXLnP6vVeud/r7y+Y+X9FC+lh/m92Zn4ELe+NtcViNv1kscoGx9nQy0Ay2kb/inAZGD1G+A2cBwYD/gJEkHRsTFwPHkWk9EfLOnMiNpAHAs8ArwaE4bDtwAfBcYAnwZuEZSCzAdeIekMVWH+QTwixrH3h24BPgcsBXwY2C6pA2BO4D35Q/mYcBAYJ+83w7ApsAc4ADg/cDbSbW9I0m1gq7eAYwEru7mkvcCHgSGAt8DLs7BDWApcAip9nEscE6+hoq35fIYBUwifR78NK9vB7wInF+1/WXAxqRazdbAObkGfBCwOL+Xm0bEYuALwGHAB4BtgWeAH3bJ+weAnYEDa1zX/sDvImJFrYuWNJD093VTzsu/A5dLekftYqrpEGAP4N3Ax4ADI2I+nf82+3QtvK9zgLL19QowDBgVEa9ExB8iDfC4B9ASEd+OiJcjYgFwEXBUQfnYO3/bfQk4G/hURCzNr30KuDEibszfxGcArcCEiHgBuA74OEAOVDuRAldXnwV+HBF3R8SqiJgKrAT2ztf3HDCW9MH7e+BxSTvl9T/k2t0rwGb5HIqI+RGxpMa5tsrPtV6r9mhEXBQRq4CppPdiG4CIuCEiHo7kDtKH+fuq9n0N+GZErIyIFyPiqYi4JiJeiIjngDNy3slB9yDg+Ih4Jr/Xd6whX58DvhYR7RGxEjgdOFydm/NOj4jnI+LF1Vz/mq59b1LQPzP/fd0KXE9+H+t0ZkQsi4jHgNtI752ViAOUdWcVqTZQbSDpgxbgv4A24KbcjDQ5p48iNfssqzxItattCsrnXfnb7pak4FL9QTwKOKJLXt5L+jCHVFuqfLB9Arg2B66uRgEndznOSFINAVItajyphnQHcDvpA/4DeZ38QXo+qTbxhKQpkjavca5KrWpYjdeq/b2yUJXnTQEkHSTpLqWm12XABFJNq6IjIl6qrEjaWNKPJT0qaTlwJzA410pHAk9HxDPd5KdiFPDrqnKaT/pbqn7/F61h/6dY87VvCyzKQb/iUVJtvV5/r1p+gVxuVh4OUNadx4DRXdK2JzefRcRzEXFyROxAunn/JUn7kT58HomIwVWPzSJiwmrO8zyp+QgASW9bl8zmJqHPA5+WtFtOXgRc1iUvm0TEmfn1m4ChksaSAtWbmveqjnNGl+NsHBG/zK9XAtT78vIddAlQOY/nRcR7SE1lbwe+UuNcD+bz/fM6FAO52fEaUm1ymxy8bwRUtVnXqQxOJjUt7hURm5MCLXmfRcAQ1e54UmtKhEXAQV3KalBEPN7NfhU3Awfme1y1LAZG5qbkiu2AyvE7/T2RmjPr5SkeSsIByrpzJfB1SSPy/ZX9SYHoani908CO+b7HctK35FXATGB5vgm/kaQBkt4laY/VnGc28E6ljgSDSE1C6yQiniJ1wvhGTvo58BGlLtsDJA3KnQRG5O1fzdfzX6R7MjNWc+iLgOMl7ZVvqG8i6WBJm+XX7wA+CGwUEe3AH0g90LYC7gOQtEfefyDpQ/QlUnl1vYYAvgT8h1Jnh81z+b9X0pQ6iuGtwIZAB/CqUueJA7rZZzPSfadluUPD6/cGczPkb4EfKXWmGCipEsCeALaStEXVsS4EzpA0Kl93i6SJdeS74jJSkLtG0k752reSdJqkCcDdpPL7as7LeNLf5RV5/1nAP+Va4Y7AcWtx7ieAEUo9Ca2BHKCsO98G/gT8kXSj+3vAJyNibn59DOnb7grgz8CPIuL2fE/kI6R2/UeAJ0lBYwtqiIi/5XPdDDyUz7c+zgUmSNo1IhYBE0lNjB2kD76v0Pnv/xekG/NX5YBVK4+tpPtQ55PKog34TJdrWEEKTETEcmAB8D+5PCB1WLgo7/8oqSnr7NWc72pSJ4p/IdUYniB19Liuu4vP95C+AEzL5/oEte+rVTsX2Ij0Xt0F/K7L658mNe0+QOqAcVI+1wPAL4EFuUlvW+C/8/lukvRcPt5e3eW7Kv8rSe/HA6QvDMtJX3qGAndHxMvAoaT7Yk+SflpwdM4LwDnAy6QymwpcXu+5Sb0K5wF/l/TkWuxnPUzhCQvNzKyEXIMyM7NScoAyM7NScoAyM7NScoAyM7NSatgAkT1h6NChMXr06EZnw8zM1sO99977ZES0dE3v0wFq9OjRtLa2dr+hmZmVlqRHa6W7ic/MzEqp8ACVf7l/n6Tr8/r2ku5WGub+ysqvtSVtmNfb8uuji86bmZmVV2/UoL5IGiiy4izSMP1jSL9wrwxBchzwTETsSPoV+Fm9kDczMyupQgNUHuvsYNIQN5VJ2PbljTluppLmjIE0FM3UvHw1sF/VvDZmZtZkiq5BnQt8lTTvDKRBM5dVjXXWzhvD4w8nD7+fX3+WN+bEeZ2kSZJaJbV2dHQUmXczM2ugwgKUpEOApRFxb3VyjU2jjtfeSIiYEhHjImJcS8ubeiWamVk/UWQ3832AQ/PQ+INIozifS5oA7S25ljSCNEozpNrUSKA9z7q5BfB0gfkzM7MSK6wGFRGnRsSIiBhNmub71oj4JGlq5cPzZsfwxtQB0/M6+fVbw0Otm5k1rUb8DuoU0qyrbaR7TBfn9ItJk561kSZqm7ya/c3MrAn0ykgSEXE7cHteXgDsWWObl4AjeiM/zWL05Bu63WbhmQf3Qk7MzNaeR5IwM7NScoAyM7NScoAyM7NS6tOjmfdH9dw3At87MrP+zwGqj6o3kJmZ9VVu4jMzs1JygDIzs1JygDIzs1JygDIzs1JygDIzs1JygDIzs1JygDIzs1Ly76B6iAdmNTPrWa5BmZlZKTlAmZlZKTlAmZlZKTlAmZlZKTlAmZlZKRUWoCQNkjRT0mxJ8yR9K6f/TNIjkmblx9icLknnSWqTNEfS7kXlzczMyq/IbuYrgX0jYoWkgcAfJf02v/aViLi6y/YHAWPyYy/ggvxsZmZNqLAaVCQr8urA/Ig17DIRuDTvdxcwWNKwovJnZmblVugPdSUNAO4FdgR+GBF3S/o34AxJ3wBuASZHxEpgOLCoavf2nLakyzEnAZMAtttuuyKz3+PKOMmgf2BsZmVVaCeJiFgVEWOBEcCekt4FnArsBOwBDAFOyZur1iFqHHNKRIyLiHEtLS0F5dzMzBqtV4Y6iohlkm4HPhwRZ+fklZJ+Cnw5r7cDI6t2GwEs7o38daeMNR8zs/6uyF58LZIG5+WNgP2BByr3lSQJOAyYm3eZDhyde/PtDTwbEUtqHNrMzJpAkTWoYcDUfB9qA2BaRFwv6VZJLaQmvVnA8Xn7G4EJQBvwAnBsgXkzM7OSKyxARcQcYLca6fuuZvsATigqP2Zm1rd4JAkzMyslBygzMyslBygzMyslBygzMyslBygzMyslBygzMyslBygzMyslBygzMyslBygzMyslBygzMyslBygzMyulXpluw/o2T2poZo3gGpSZmZWSa1DWI1zLMrOe5hqUmZmVkgOUmZmVkgOUmZmVUmEBStIgSTMlzZY0T9K3cvr2ku6W9JCkKyW9NadvmNfb8uuji8qbmZmVX5E1qJXAvhHxbmAs8GFJewNnAedExBjgGeC4vP1xwDMRsSNwTt7OzMyaVGEBKpIVeXVgfgSwL3B1Tp8KHJaXJ+Z18uv7SVJR+TMzs3Ir9B6UpAGSZgFLgRnAw8CyiHg1b9IODM/Lw4FFAPn1Z4GtahxzkqRWSa0dHR1FZt/MzBqo0AAVEasiYiwwAtgT2LnWZvm5Vm0p3pQQMSUixkXEuJaWlp7LrJmZlUqv9OKLiGXA7cDewGBJlR8IjwAW5+V2YCRAfn0L4OneyJ+ZmZVPkb34WiQNzssbAfsD84HbgMPzZscA1+Xl6Xmd/PqtEfGmGpSZmTWHIoc6GgZMlTSAFAinRcT1ku4HrpD0XeA+4OK8/cXAZZLaSDWnowrMm5mZlVxhASoi5gC71UhfQLof1TX9JeCIovJjZmZ9i0eSMDOzUnKAMjOzUvJ0G9ZrPCWHma0N16DMzKyUHKDMzKyUHKDMzKyUfA/KSsX3qcyswjUoMzMrJQcoMzMrJQcoMzMrJQcoMzMrJQcoMzMrJQcoMzMrJQcoMzMrJQcoMzMrJQcoMzMrJQcoMzMrJQcoMzMrpcIClKSRkm6TNF/SPElfzOmnS3pc0qz8mFC1z6mS2iQ9KOnAovJmZmblV+Rgsa8CJ0fEXyRtBtwraUZ+7ZyIOLt6Y0m7AEcB7wS2BW6W9PaIWFVgHs3MrKQKq0FFxJKI+Etefg6YDwxfwy4TgSsiYmVEPAK0AXsWlT8zMyu3ugKUpHetz0kkjQZ2A+7OSSdKmiPpEklb5rThwKKq3dqpEdAkTZLUKqm1o6NjfbJlZmYlVm8N6kJJMyV9XtLgtTmBpE2Ba4CTImI5cAHwD8BYYAnw/cqmNXaPNyVETImIcRExrqWlZW2yYmZmfUhdASoi3gt8EhgJtEr6haQPdbefpIGk4HR5RPwqH+uJiFgVEa8BF/FGM157Pn7FCGBx3VdiZmb9St33oCLiIeDrwCnAB4DzJD0g6Z9qbS9JwMXA/Ij4QVX6sKrNPgrMzcvTgaMkbShpe2AMMHNtLsbMzPqPunrxSdoVOBY4GJgBfCT3ztsW+DPwqxq77QN8GvirpFk57TTg45LGkprvFgKfA4iIeZKmAfeTegCe4B58ZmbNq95u5ueTmuNOi4gXK4kRsVjS12vtEBF/pPZ9pRtXd5KIOAM4o848mZlZP1ZvgJoAvFip0UjaABgUES9ExGWF5c7MzJpWvfegbgY2qlrfOKeZmZkVot4ANSgiVlRW8vLGxWTJzMys/gD1vKTdKyuS3gO8uIbtzczM1ku996BOAq6SVPld0jDgyGKyZGZmVmeAioh7JO0EvIPUM++BiHil0JyZmVlTW5vRzPcARud9dpNERFxaSK7MzKzp1ftD3ctI4+fNAio/ng3AAcrMzApRbw1qHLBLRLxp8FYzM7Mi1NuLby7wtiIzYmZmVq3eGtRQ4H5JM4GVlcSIOLSQXJmZWdOrN0CdXmQmzMzMuqq3m/kdkkYBYyLiZkkbAwOKzZqZmTWzeqd8/yxwNfDjnDQcuLaoTJmZmdXbSeIE0vxOy+H1yQu3LipTZmZm9d6DWhkRL6dJckHSW0i/gzLrdaMn39DtNgvPPLgXcmJmRao3QN0h6TRgI0kfAj4P/Ka4bPWeej7szMys99XbxDcZ6AD+Spqi/Uag5ky6ZmZmPaGuABURr0XERRFxREQcnpfX2MQnaaSk2yTNlzRP0hdz+hBJMyQ9lJ+3zOmSdJ6kNklzqqf3MDOz5lNvL75HJC3o+uhmt1eBkyNiZ2Bv4ARJu5BqY7dExBjglrwOcBAwJj8mAResw/WYmVk/sTZj8VUMAo4Ahqxph4hYAizJy89Jmk/qnj4RGJ83mwrcDpyS0y/NNbO7JA2WNCwfx8zMmky9TXxPVT0ej4hzgX3rPYmk0cBuwN3ANpWgk58r3dWHA4uqdmvPaV2PNUlSq6TWjo6OerNgZmZ9TL3TbVTfD9qAVKParM59NwWuAU6KiOWVruq1Nq2R9qb7XBExBZgCMG7cOHd1NzPrp+pt4vt+1fKrwELgY93tJGkgKThdHhG/yslPVJruJA0Dlub0dmBk1e4jgMWYmVlTqncsvg+u7YGVqkoXA/Mj4gdVL00HjgHOzM/XVaWfKOkKYC/gWd9/MjNrXvU28X1pTa93CUAV+wCfBv4qaVZOO40UmKZJOg54jNThAtJvqyYAbcALwLH15M3MzPqntenFtweplgPwEeBOOndq6CQi/kjt+0oA+9XYPkhj/pmZma3VhIW7R8RzAJJOB66KiH8tKmNmZtbc6h3qaDvg5ar1l4HRPZ4bMzOzrN4a1GXATEm/JnX9/ihwaWG5MltPHvHcrO+rtxffGZJ+C7wvJx0bEfcVly0zM2t29TbxAWwMLI+I/wbaJW1fUJ7MzMzqHiz2m6Tx8k7NSQOBnxeVKTMzs3prUB8FDgWeB4iIxdQ51JGZmdm6qDdAvZx/pxQAkjYpLktmZmb1B6hpkn4MDJb0WeBm4KLismVmZs2u3l58Z0v6ELAceAfwjYiYUWjOzMysqXUboCQNAH4fEfsDDkpmZtYrum3ii4hVwAuStuiF/JiZmQH1jyTxEmlU8hnknnwAEfGFQnJl1gvqGW0CPOKEWaPUG6BuyA8zM7NescYAJWm7iHgsIqb2VobMzMyg+3tQ11YWJF1TcF7MzMxe112Aqp5wcIciM2JmZlatuwAVq1nulqRLJC2VNLcq7XRJj0ualR8Tql47VVKbpAclHbg25zIzs/6nu04S75a0nFST2igvk9cjIjZfw74/A87nzfNGnRMRZ1cnSNoFOAp4J7AtcLOkt+cu7mZm1oTWGKAiYsC6Hjgi7pQ0us7NJwJXRMRK4BFJbcCewJ/X9fxmZta3rc18UD3lRElzchPgljltOLCoapv2nGZmZk2qtwPUBcA/AGOBJcD3c7pqbFvznpekSZJaJbV2dHQUk0szM2u4Xg1QEfFERKyKiNdIo6HvmV9qB0ZWbToCWLyaY0yJiHERMa6lpaXYDJuZWcP0aoCSNKxq9aNApYffdOAoSRvmqeTHADN7M29mZlYu9Q51tNYk/RIYDwyV1A58ExgvaSyp+W4h8DmAiJgnaRpwP/AqcIJ78FlZ1DNmn8frM+t5hQWoiPh4jeSL17D9GcAZReXHzMz6lkb04jMzM+uWA5SZmZWSA5SZmZWSA5SZmZVSYZ0kzJqJe/qZ9TzXoMzMrJQcoMzMrJQcoMzMrJQcoMzMrJQcoMzMrJQcoMzMrJQcoMzMrJQcoMzMrJQcoMzMrJQcoMzMrJQcoMzMrJQcoMzMrJQcoMzMrJQKC1CSLpG0VNLcqrQhkmZIeig/b5nTJek8SW2S5kjavah8mZlZ31DkdBs/A84HLq1KmwzcEhFnSpqc108BDgLG5MdewAX52azf8JQcZmunsBpURNwJPN0leSIwNS9PBQ6rSr80kruAwZKGFZU3MzMrv96+B7VNRCwByM9b5/ThwKKq7dpz2ptImiSpVVJrR0dHoZk1M7PGKUsnCdVIi1obRsSUiBgXEeNaWloKzpaZmTVKbweoJypNd/l5aU5vB0ZWbTcCWNzLeTMzsxIpspNELdOBY4Az8/N1VeknSrqC1Dni2UpToJl15s4W1iwKC1CSfgmMB4ZKage+SQpM0yQdBzwGHJE3vxGYALQBLwDHFpUvMzPrGwoLUBHx8dW8tF+NbQM4oai8mPUV9dSOzJpFWTpJmJmZdeIAZWZmpeQAZWZmpeQAZWZmpeQAZWZmpeQAZWZmpeQAZWZmpdTbI0mYWS/waBPWH7gGZWZmpeQAZWZmpeQAZWZmpeQAZWZmpeQAZWZmpeQAZWZmpeQAZWZmpeQAZWZmpeQAZWZmpeQAZWZmpdSQoY4kLQSeA1YBr0bEOElDgCuB0cBC4GMR8Uwj8mdmiYdMskZq5Fh8H4yIJ6vWJwO3RMSZkibn9VMakzWz/q+e4NNTx3EQ65sa/d6WqYlvIjA1L08FDmtgXszMrMEaFaACuEnSvZIm5bRtImIJQH7eutaOkiZJapXU2tHR0UvZNTOz3taoJr59ImKxpK2BGZIeqHfHiJgCTAEYN25cFJVBMzNrrIbUoCJicX5eCvwa2BN4QtIwgPy8tBF5MzOzcuj1ACVpE0mbVZaBA4C5wHTgmLzZMcB1vZ03MzMrj0Y08W0D/FpS5fy/iIjfSboHmCbpOOAx4IgG5M3MGqjRvcasXHo9QEXEAuDdNdKfAvbr7fyYmVk5NfJ3UGbWJHrqN1fWXMr0OygzM7PXOUCZmVkpuYnPzPqdnups4U4bjeUAZWZNyffFys9NfGZmVkquQZlZn+KaT/NwDcrMzErJAcrMzErJAcrMzErJ96DMzNaDu6IXxwHKzKxgDmLrxgHKzKwJ9YXekA5QZmZ9RF8IKj3JAcrMrASaLfjUw734zMyslBygzMyslBygzMyslEoXoCR9WNKDktokTW50fszMrDFKFaAkDQB+CBwE7AJ8XNIujc2VmZk1QqkCFLAn0BYRCyLiZeAKYGKD82RmZg1Qtm7mw4FFVevtwF7VG0iaBEzKqyskPbiW5xgKPLnOOex/XB6duTw6c3l05vLobKjO6pHyGFUrsWwBSjXSotNKxBRgyjqfQGqNiHHrun9/4/LozOXRmcujM5dHZ0WXR9ma+NqBkVXrI4DFDcqLmZk1UNkC1D3AGEnbS3orcBQwvcF5MjOzBihVE19EvCrpROD3wADgkoiY18OnWefmwX7K5dGZy6Mzl0dnLo/OCi0PRUT3W5mZmfWysjXxmZmZAQ5QZmZWUk0ToJplCCVJl0haKmluVdoQSTMkPZSft8zpknReLpM5knav2ueYvP1Dko5pxLX0BEkjJd0mab6keZK+mNObskwkDZI0U9LsXB7fyunbS7o7X9uVuZMSkjbM62359dFVxzo1pz8o6cDGXFHPkDRA0n2Srs/rTVsekhZK+qukWZJac1pj/l8iot8/SB0uHgZ2AN4KzAZ2aXS+CrrW9wO7A3Or0r4HTM7Lk4Gz8vIE4Lek35/tDdyd04cAC/Lzlnl5y0Zf2zqWxzBg97y8GfA30jBaTVkm+bo2zcsDgbvzdU4DjsrpFwL/lpc/D1yYl48CrszLu+T/ow2B7fP/14BGX996lMuXgF8A1+f1pi0PYCEwtEtaQ/5fmqUG1TRDKEXEncDTXZInAlPz8lTgsKr0SyO5CxgsaRhwIDAjIp6OiGeAGcCHi899z4uIJRHxl7z8HDCfNGJJU5ZJvq4VeXVgfgSwL3B1Tu9aHpVyuhrYT5Jy+hURsTIiHgHaSP9nfY6kEcDBwE/yumji8liNhvy/NEuAqjWE0vAG5aURtomIJZA+sIGtc/rqyqVflldujtmNVGto2jLJzVmzgKWkD46HgWUR8WrepPraXr/u/PqzwFb0o/IAzgW+CryW17eiucsjgJsk3as0tBw06P+lVL+DKlC3Qyg1qdWVS78rL0mbAtcAJ0XE8vSlt/amNdL6VZlExCpgrKTBwK+BnWttlp/7dXlIOgRYGhH3ShpfSa6xaVOUR7ZPRCyWtDUwQ9IDa9i20PJolhpUsw+h9ESudpOfl+b01ZVLvyovSQNJwenyiPhVTm7qMgGIiGXA7aR7B4MlVb6wVl/b69edX9+C1ITcX8pjH+BQSQtJTf/7kmpUzVoeRMTi/LyU9AVmTxr0/9IsAarZh1CaDlR60RwDXFeVfnTuibM38Gyuvv8eOEDSlrm3zgE5rc/J9wcuBuZHxA+qXmrKMpHUkmtOSNoI2J90X+424PC8WdfyqJTT4cCtke6CTweOyr3atgfGADN75yp6TkScGhEjImI06XPh1oj4JE1aHpI2kbRZZZn0dz6XRv2/NLrHSG89SL1N/kZqb/9ao/NT4HX+ElgCvEL6FnMcqY38FuCh/DwkbyvSBJEPA38FxlUd519IN3rbgGMbfV3rUR7vJTUtzAFm5ceEZi0TYFfgvlwec4Fv5PQdSB+obcBVwIY5fVBeb8uv71B1rK/lcnoQOKjR19YDZTOeN3rxNWV55OuenR/zKp+Vjfp/8VBHZmZWSs3SxGdmZn2MA5SZmZWSA5SZmZWSA5SZmZWSA5SZmZWSA5RZD5H0M0mHd79lj51vrKQJvXU+s97mAGVWAvmHjmv7/ziW9JuutTlPswxvZv2AA5TZOpJ0dJ4DZ7aky3Ly+yX9SdKCSm1K0qaSbpH0lzzPzsScPlppnqofAX8BRkq6QFKrquZqytvukY87W2k+py2AbwNH5nl7jsyjAFwi6R6luY0q5/mMpKsk/YY0COgwSXfm/eZKel9vlptZvfxDXbN1IOmdwK9IA2s+KWkI8ANgE+BIYCdgekTsmGstG0capHYocBdpKJxRpHly/jHSVAVIGhIRT0saQPrF/heAB/LjyIi4R9LmwAvAp0i/3D8x7/ufwP0R8fM8nNFM0ujtRwDfBXbNxz4ZGBQRZ+TzbBxpKhKzUnF132zd7AtcHRFPAuQPfoBrI+I14H5J2+RtBfynpPeTpnQYDlRee7QSnLKP5SkO3kKabHEX0lBNSw4aTLoAAAFdSURBVCLinnyu5QA1RmQ/gDTw6Zfz+iBgu7w8IyIq84TdA1ySB9G9NiJmrUc5mBXGTXxm60bUnj5gZZdtAD4JtADviYixwBOk4AHw/Osbp0FGvwzsFxG7Ajfk7VZ3rlp5+ueIGJsf20XE/K7niTSp5fuBx4HLJB1dx7HNep0DlNm6uYVU29kKUtPcGrbdgjTn0CuSPkhq2qtlc1IgeTbXvg7K6Q8A20raI59rs9xs+BxpGvuK3wP/nkdwR9JutU4iaVTOz0Wkkd537/ZqzRrATXxm6yAi5kk6A7hD0irSCOGrcznwG0mtpNHUa04AFxGzJd1HGkV6AfA/Of1lSUcC/z9PkfEiaZqM24DJSrPj/j/gO6S5jObkILUQOKTGqcYDX5H0CrACcA3KSsmdJMzMrJTcxGdmZqXkAGVmZqXkAGVmZqXkAGVmZqXkAGVmZqXkAGVmZqXkAGVmZqX0v+A1yTSn+p6EAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot distribution of character counts in useful reviews subset\n",
    "text_length.plot(kind='hist', bins='fd', title='Useful Reviews Character Count')\n",
    "plt.xlabel('characters')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../img/useful_reviews_char_count.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that turns a sequence of length 100+1 into an input chunk (first 100 char) and target chunk (last 100 char).\n",
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The unique characters in the file / number of output layer nodes.\n",
    "vocab = sorted(set(text))\n",
    "\n",
    "# Creating a mapping from unique characters to indices\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "# converting text data into indices\n",
    "text_as_int = np.array([char2idx[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training and validation folds\n",
    "text_as_int_tr = text_as_int[:int(text_as_int.shape[0]*.9)]\n",
    "text_as_int_val = text_as_int[int(text_as_int.shape[0]*.9):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = '../training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "# options for saving checkpoints\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wednesday Model / LSTM w Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The maximum length sentence we want for a single input in characters\n",
    "seq_length = 256\n",
    "\n",
    "# number of samples given sequence length\n",
    "examples_per_epoch = len(text_as_int_tr)//(seq_length+1)\n",
    "\n",
    "# Create training, validation examples / targets\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int_tr)\n",
    "char_dataset_val = tf.data.Dataset.from_tensor_slices(text_as_int_val)\n",
    "\n",
    "# combine consecutive elements of a data set into batches\n",
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "sequences_val = char_dataset_val.batch(seq_length+1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use function to split sequences into input and target columns\n",
    "dataset = sequences.map(split_input_target)\n",
    "dataset_val = sequences_val.map(split_input_target)\n",
    "\n",
    "# Batch size\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "# group samples (input, target) into batches\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "dataset_val = dataset_val.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function for neural net\n",
    "def loss(labels, logits):\n",
    "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM\n",
    "def build_model_lstm(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "  model = tf.keras.Sequential([\n",
    "      # embedding layer. ?? what does it do ??\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                              batch_input_shape=[batch_size, None]),\n",
    "      # LSTM layer. return full sequence to output layer\n",
    "    tf.keras.layers.LSTM(rnn_units,\n",
    "                        recurrent_initializer='glorot_uniform',\n",
    "                        dropout=0.5,\n",
    "                        return_sequences=True,\n",
    "                        stateful=True\n",
    "                        ),\n",
    "    tf.keras.layers.LSTM(rnn_units,\n",
    "                        recurrent_initializer='glorot_uniform',\n",
    "                        dropout=0.5,\n",
    "                        return_sequences=True,\n",
    "                        stateful=True\n",
    "                        ),\n",
    "    tf.keras.layers.LSTM(rnn_units,\n",
    "                        recurrent_initializer='glorot_uniform',\n",
    "                        dropout=0.5,\n",
    "                        return_sequences=True,\n",
    "                        stateful=True\n",
    "                        ),\n",
    "      # output is a matrix of shape(seq length, vocab size)\n",
    "    tf.keras.layers.Dense(vocab_size)\n",
    "  ])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate strings of variable length\n",
    "def generate_text(model, start_string, num_generate=1000, temperature=1.0):\n",
    "  # Evaluation step (generating text using the learned model)\n",
    "\n",
    "  # Number of characters to generate\n",
    "  num_generate = num_generate\n",
    "\n",
    "  # Converting our start string to numbers (vectorizing)\n",
    "  input_eval = [char2idx[s] for s in start_string]\n",
    "  input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "  # Empty string to store our results\n",
    "  text_generated = []\n",
    "\n",
    "  # Low temperatures results in more predictable text.\n",
    "  # Higher temperatures results in more surprising text.\n",
    "  # Experiment to find the best setting.\n",
    "  temperature = temperature\n",
    "\n",
    "  # Here batch size == 1\n",
    "  model.reset_states()\n",
    "  for i in range(num_generate):\n",
    "      predictions = model(input_eval)\n",
    "      # remove the batch dimension\n",
    "      predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "      # using a categorical distribution to predict the character returned by the model\n",
    "      predictions = predictions / temperature\n",
    "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "      # We pass the predicted character as the next input to the model\n",
    "      # along with the previous hidden state\n",
    "      input_eval = tf.expand_dims([predicted_id], 0)\n",
    "    \n",
    "      text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "  return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (32, None, 256)           39168     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (32, None, 512)           1574912   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (32, None, 512)           2099200   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (32, None, 512)           2099200   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (32, None, 153)           78489     \n",
      "=================================================================\n",
      "Total params: 5,890,969\n",
      "Trainable params: 5,890,969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# more efficient than adding layers method\n",
    "model_lstm = build_model_lstm(\n",
    "  vocab_size = len(vocab),\n",
    "  embedding_dim=embedding_dim,\n",
    "  rnn_units=rnn_units,\n",
    "  batch_size=BATCH_SIZE)\n",
    "# print model architecture table\n",
    "model_lstm.summary()\n",
    "# model needs to be compiled\n",
    "model_lstm.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x1750dc99e48>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lstm.load_weights('../training_checkpoints/lstm_training_checkpoints\\\\ckpt_18')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # number of passes over the data\n",
    "# EPOCHS=50\n",
    "# # fit model\n",
    "# history = model_lstm.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback], validation_data=dataset_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wednesday Model / LSTM w Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train for 872 steps, validate for 96 steps  \n",
    "Epoch 1/50  \n",
    "872/872 [==============================] - 2656s 3s/step - loss: 2.3646 - val_loss: 1.7744  \n",
    "Epoch 2/50  \n",
    "872/872 [==============================] - 2872s 3s/step - loss: 1.7112 - val_loss: 1.5699  \n",
    "Epoch 3/50  \n",
    "872/872 [==============================] - 2873s 3s/step - loss: 1.5818 - val_loss: 1.4935  \n",
    "Epoch 4/50  \n",
    "872/872 [==============================] - 2828s 3s/step - loss: 1.5175 - val_loss: 1.4489  \n",
    "Epoch 5/50  \n",
    "872/872 [==============================] - 2861s 3s/step - loss: 1.4769 - val_loss: 1.4176  \n",
    "Epoch 6/50  \n",
    "872/872 [==============================] - 2862s 3s/step - loss: 1.4479 - val_loss: 1.3962  \n",
    "Epoch 7/50  \n",
    "872/872 [==============================] - 2857s 3s/step - loss: 1.4259 - val_loss: 1.3801  \n",
    "Epoch 8/50  \n",
    "872/872 [==============================] - 2894s 3s/step - loss: 1.4086 - val_loss: 1.3649  \n",
    "Epoch 9/50  \n",
    "872/872 [==============================] - 2836s 3s/step - loss: 1.3940 - val_loss: 1.3548  \n",
    "Epoch 10/50  \n",
    "872/872 [==============================] - 2824s 3s/step - loss: 1.3824 - val_loss: 1.3449  \n",
    "Epoch 11/50  \n",
    "872/872 [==============================] - 2822s 3s/step - loss: 1.3720 - val_loss: 1.3387  \n",
    "Epoch 12/50  \n",
    "872/872 [==============================] - 2792s 3s/step - loss: 1.3631 - val_loss: 1.3298  \n",
    "Epoch 13/50  \n",
    "872/872 [==============================] - 2780s 3s/step - loss: 1.3548 - val_loss: 1.3255  \n",
    "Epoch 14/50  \n",
    "872/872 [==============================] - 4831s 6s/step - loss: 1.3478 - val_loss: 1.3188  \n",
    "Epoch 15/50  \n",
    "872/872 [==============================] - 4370s 5s/step - loss: 1.3413 - val_loss: 1.3138  \n",
    "Epoch 16/50  \n",
    "872/872 [==============================] - 4649s 5s/step - loss: 1.3350 - val_loss: 1.3084  \n",
    "Epoch 17/50  \n",
    "872/872 [==============================] - 3699s 4s/step - loss: 1.3295 - val_loss: 1.3050  \n",
    "Epoch 18/50  \n",
    "872/872 [==============================] - 3146s 4s/step - loss: 1.3245 - val_loss: 1.3008  \n",
    "Epoch 19/50  \n",
    "534/872 [=================>............] - ETA: 21:01 - loss: 1.3219  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoint 15 (lowest training loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (1, None, 256)            39168     \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (1, None, 512)            1574912   \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (1, None, 512)            2099200   \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (1, None, 512)            2099200   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (1, None, 153)            78489     \n",
      "=================================================================\n",
      "Total params: 5,890,969\n",
      "Trainable params: 5,890,969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# rebuild model with batch size = 1\n",
    "model_lstm = build_model_lstm(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "# load weights from checkpoint\n",
    "model_lstm.load_weights('../training_checkpoints/lstm_training_checkpoints\\\\ckpt_18')\n",
    "# ?? ??\n",
    "model_lstm.build(tf.TensorShape([1, None]))\n",
    "# print model architecture table\n",
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SOR><SOR>I have always walked about 4 minutes to be a lot of roll, but my opinion is in the drink to the back of each family because the entire presentation is beautiful and bone chance to sitting very correctly what you will not be back with their hot southern omelets. They were absolutely clean, and so delicious!\n",
      "\n",
      "At least that was always amazing! I was very really good explanation. I was amazing and get at all and made you feel great. They of course, and I was still tasting better than the other place is heaven. I was colorful for my last and I didn't really had to ask for the rib eye.\n",
      "\n",
      "We had letting the bar of the chance for all the service to get it and wonderful wings so I only received and included the entire time that we're all into the business the classes for a pillow food can't even thought they say so they have stopping in a tiny reservation they offered a short of that time. You find a big case, because that the bar in the table and then I was able to me if you met it as a touch.\n",
      "\n",
      "We saw a lot of sample perfect months and the seasoning that we had here it was heading up to the house and I have seen in the 13 hours to enjoy his house. \n",
      "\n",
      "Service was 2 places, the pizza is an inside if you were gonna, but this is a complaint of this time and had a lot of personal bread.  The service of the combination and artists are fresh, it's as flavorful, I walked around the Stars, b\n",
      "<SOR>On the day to the parking level of Princess Diets.  The music creamy and he did not go to the new friend and it is a high experience was surprised off the other candied years to try it and he knows why a FREE DUIN ARCE CHARE \n",
      "\n",
      "The bread stuffed tuesday to admit the animal attitude here. I always lived in others at the first time. \n",
      "\n",
      "Strange out for me and the most professional review and was so rich. I mean was there for as the sunstant change won't be trained in the top of the day, it was best on the dining attitude. The all grilled pie is a fan of them at 3 square streets explore which is also offered to go to the most cool people.  I can get the broth service and individuals at the best time we were open to the food it was thinking it was thinking.  I'm always trying to bring them so friendly and all the prices in some of the great course shows here. I always see the fresh buffet in the area and we liked the counter adventures before we ordered the work to a wait since it was there of my husband Hawaiian food and low that are looking for the same tone of the all the bread! I also been great and cooked and that I can just want to bring air number of flavors. \n",
      "\n",
      "As its made to the bread was good and they are looking for it to be going to get a real down so we got a warm sandwich headed to you! With all the same dessert growing in carrots here and see beef tomatoes, space on the \n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model_lstm, start_string=u\"<SOR>\", num_generate=1400, temperature=0.7))\n",
    "print(generate_text(model_lstm, start_string=u\"<SOR>\", num_generate=1400, temperature=0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SOR>\n",
      "They do not be said that the restaurant is really good and we saw a lot of dessert.  The parking local cocktail was as so much beautiful, you charge your life, and they do the Chocolate Honey's way.  I love the view of the bad looking forward by the staff as well as the side of each other restaurant.  I am so good. One car was extremely center paying it wyer in 201.  The past to carry for a variety of sauce.  They sell the walk in a window, but make the both director facility; but it was a little concert. \n",
      "\n",
      "When you enter, it is a good room at the bar, and soft price is not to be. They serve the front menu the most sort of Markshird is very highly. I'm in the Manlo's Cake, but I was able there were not relaxing for the one for their busy tones. Landscaping training the way.  The spice was time as I'm glad they are slightly busy down the food continual couple of the flavors are the best American but the service are not only dined.\n",
      "\n",
      "Food\n",
      "Great favorite is a crazy latte was delicious. I am stock inside the bar work looked about the place on my browns.<EOR><SOR>It is a something that I'm accept 6, the service was very friendly admitted at the guy change the car. Choices that they have a giant community, the bread who let's recommend the shaker ice cream to come back for myster. This is a new ginger little time else. They were good but I could take about Branch to and continue this\n",
      "<SOR>There is a camp with a tour land savory, and an excellent hour. I always like the chubo consultation were prepared and enjoyed it.  He is helpful and the prices are served on all and the steps ur my point. She left, and there is a different bite of Sun Brunch.... just like this place?<EOR><SOR>A large restaurant had a new store I had feel come for the entire hot sauce about this place members could have a big bit on their garage different companies at the Parmesan brisket of differents that has been adored to Korean grand next time, and I was served with a strawberries, I couldn't do take a nice skin pancakes I put a starter and entering our meat. I bought it to braving here, with starters, bacon, and trail places around to the first time to be Dr. Arepa where they got later, I told me in a couple of different drink and a mouth was plenty of voice. They will continue to get me to perfect and decided to save Chandler there. I love that it's not to come back again, everything you will find was always pretty and there's a good tea that would be convinced. We had more than 12 best service!<EOR><SOR>Even for a new place to have a lot of paper that I have been two training traffic and people as the chocolate visit that has a very perfect concept. It's a shoe new to a large fish for extra connection of salt that you can heave a nice collection of drinks and producal fire the order but\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model_lstm, start_string=u\"<SOR>\", num_generate=1400, temperature=0.8))\n",
    "print(generate_text(model_lstm, start_string=u\"<SOR>\", num_generate=1400, temperature=0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate block text of variable length\n",
    "def generate_blocktext(model, start_string, num_generate=1000, temperature=0.6):\n",
    "  # Evaluation step (generating text using the learned model)\n",
    "\n",
    "  # Converting our start string to numbers (vectorizing)\n",
    "  input_eval = [char2idx[s] for s in start_string]\n",
    "  input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "  # Here batch size == 1\n",
    "  model.reset_states()\n",
    "  for i in range(num_generate):\n",
    "      predictions = model(input_eval)\n",
    "      # remove the batch dimension\n",
    "      predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "      # using a categorical distribution to predict the character returned by the model\n",
    "      predictions = predictions / temperature\n",
    "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "      # We pass the predicted character as the next input to the model\n",
    "      # along with the previous hidden state\n",
    "      input_eval = tf.expand_dims([predicted_id], 0)\n",
    "    \n",
    "      print(idx2char[predicted_id], end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "generate_blocktext(model_simplegru, '\\n', 500000, temperature=0.7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
