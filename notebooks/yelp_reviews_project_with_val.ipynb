{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# for data processing for Tensorflow\n",
    "import numpy as np\n",
    "# for saving Tensorflow checkpoints\n",
    "import os\n",
    "# for loading and manipulating data\n",
    "import pandas as pd\n",
    "# for neural networks\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "review.json is 5.2 GB uncompressed with 6685900 lines corresponding to reviews and review metadata.  \n",
    "It is too large to load completely into memory so I will load pieces of it as needed (pandas chunksize argument.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time #4min 38s\n",
    "# # load data using chunksize option\n",
    "# df_chunks = pd.read_json('../data/yelp_dataset/review.json', lines=True, chunksize=400000)\n",
    "\n",
    "# # list to hold chunks after querying\n",
    "# chunks = [chunk[(chunk.stars == 5.0) & (chunk.useful > 0)] for chunk in df_chunks]\n",
    "\n",
    "# # dataframe of useful 5-star reviews\n",
    "# df = pd.concat(chunks)\n",
    "\n",
    "# # save csv for faster loading in the future\n",
    "# df.to_csv('../data/useful_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\K\\Miniconda3\\envs\\tf-gpu-cuda10\\lib\\site-packages\\numpy\\lib\\arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# load data from csv for a faster start\n",
    "df = pd.read_csv('../data/useful_reviews.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add <SOR> and <EOR> tokens to delimit reviews\n",
    "df.text = df.text.apply(lambda x: '<SOR>' + x + '<EOR>')\n",
    "df_copy = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "598\n",
      "946699\n"
     ]
    }
   ],
   "source": [
    "# minimum number of useful votes to include\n",
    "n = 60\n",
    "\n",
    "# number of reviews in subset\n",
    "print(df_copy[df_copy.useful >= n].shape[0])\n",
    "\n",
    "# number of characters in subset\n",
    "print(len(df_copy[df_copy.useful >= n].text.str.cat()))\n",
    "\n",
    "# block of text to serve as model training data\n",
    "text = df_copy[df_copy.useful >= n].text.str.cat()\n",
    "\n",
    "# dataframe to allow for eda plots\n",
    "df = df_copy[df_copy.useful >= n]\n",
    "\n",
    "# subset for eda plotting about comment characteristics\n",
    "text_length = df.text.str.len()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1194239 reviews have been voted useful.  \n",
    "591242 reviews have more than 1 useful vote.  \n",
    "335812 reviews have more than 2 useful votes.  \n",
    "211232 reviews have more than 3 useful votes.  \n",
    "31020 reviews have more than 10 useful votes.  \n",
    "5696 reviews have 25+ useful votes.*  \n",
    "3733 reviews have 30+ useful votes.  \n",
    "1812 reviews have 40+ useful votes.  \n",
    "*For reduced computation time during this prototyping phase, I will use this reduced data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments with at least 30 useful votes have a mean length of 1458 characters.  \n",
    "Comments with at least 25 useful votes have a mean length of 1399 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5696.000000\n",
       "mean     1399.324965\n",
       "std      1011.935319\n",
       "min        66.000000\n",
       "25%       648.750000\n",
       "50%      1160.500000\n",
       "75%      1869.250000\n",
       "max      5010.000000\n",
       "Name: text, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_length.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['<SOR>I received the product as expected and on time.  Thanks!<EOR>'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text[text_length == 66].values # shortest review. user and business id are hashed and requiring merging a different json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['<SOR>The ratings are not a lie and I have a new Top 3 favourite spot in Toronto. There\\'s a lot of great things about Richmond Station.. but if there is one takeaway from my review, let it be this.  If you want a phenomenal meal, ask specifically for the chef pass and the chef tasting menu.  Not only is it a feast for your taste buds and eyes... it is a feast of all senses.  \\n\\nFrom the outside, you wouldnt think automatically a restaurant of this calibre and space would be hiding behind a simple window golden font of Richmond Station and a tiny signage with  simple words of \\'Restaurant\\'.  If you peered in, you\\'d see an overflowing amount of people enjoying a lot of interesting dishes.  You\\'ll also notice a lot of people coming in to only be sadly turned away.  \\n\\nThe space is warm and welcoming... there\\'s no pretentious airs here.  It\\'s quite different from my other 2 favourite higher end spots (Buca and Grey Gardens).  The atmosphere here is relaxed and if anything, more casual ... though do not mistaken this for a bar atmosphere.  It\\'s still refined with its wood accents and clean lines but the staff creates more of an approachable vibe.  You can see the humour in the hallway to the bathrooms where they have snapshots and commentary of the restaurant.  One of the chefs has a Calgary Flames hat ... the snap of him has \"Get him a leafs hat\".  I will say the tables are kinda close... we heard other table\\'s conversation more than a few times.  \\n\\nBefore I go into the food... I do have to say that Richmond station is possibly my 3rd favourite only because of the kitchen pacing.  For us, our first two dishes were the oysters and charcuterie.  Though they were good... it was 50 minutes after being seated that we got our charcuterie.  If the pacing was better, this would have been my top favourite. \\n\\nWith the chef menu at $65, it does seem a bit pricey but let me tell you that you will feast and be blown away by what you\\'re given.  We were offered a total of 7 dishes with a final offering of petit four ... so 8 dishes really.  So if you\\'re concerned you will be not getting any value... put those fears aside & just enjoy the show.\\n\\nChef Menu \\n\\nOysters on the half shell - Briney & bright with minimal metallic flavour ... the addition of the horseradish & lemons makes this starter pop.  The oysters were a generous size (not too big) and perfectly opened... not a speck of shell or sand.  You\\'re treated to 2 oysters each.  4.5/5\\n\\nIn house made Charcuterie - If someone says no to this beauty of a platter, I dont think we can be friends.  With 5 types of offerings & a side of pickled vegetables & bold savoury mustards, this was just a great way to perk my taste buds more.  The pickled beats was a perfect pairing to the fatty rich meat.  I wish I could have had more.  The bacalhau (spelling... salted cod really) was just so tender after breaking through the greaseless crispy shell.   5/5\\n\\nBrassica Caesar - This is an interesting take on a Caesar salad.  Instead of the mayo bland romaine lettuce, they used broccoli, cauliflower, shredded cabbage, roasted sprouts, with a health dose of roasted nuts (love their crunch and smokiness), parmigana, and yes... anchovies.  BUT these anchovies are tender savoury bursts ... it\\'s good.  Trust the chef.  I love the take on this classic.  4.5/5\\n\\nRoasted Cod - OH YES... definitely a perfectly cooked and seared fish.  The perfect crispy sear gave way to a tender white fish.  Seasoned so well...it still tasted of sweet fresh fish.  I liked this a lot but what was also great was the bold pairing of the red pepper rouille that sat on top of the sourdough bread.  I think I lost my piece of red pepper bread to a hungrier cub cause it was that good. 5/5\\n\\nSirloin - I learned they dry age these in house... up to 6 weeks and you can honestly taste the nuances.  This was very savoury with the perfect sear.  It\\'s just so ... meaty and beefy in flavour but so tender in texture.  I wouldnt say it\\'s spongey soft like a tenderloin but this might be one of the better sirloins I\\'ve eaten.  The bloodthirsty carnivore in me loved every bite.  5/5\\n\\nStation Burger - Oh hell yes... It has been more than 4 years since I\\'ve eaten a burger and wow, what a bite to break that up.  Damn.  Ok, I get why this has been on the menu since the start.  It\\'s cooked to a juicy medium rare and served with a lot of great flavours.  You have the soft milk bun ready to sop up all the juices, bold acidity of the beet chutney and pickles that cut through the beef, the mild sweetness of beets, aged cheddar for a bite, and aioli for the lucious texture. 5/5\\n\\nCreamsicle - Deconstructured with many components.  It\\'s more subtle orange flavours paired with licorice flavoured fennel and graham.  Orange white chocolate mousse, grand marnier creme, fennel sherbert, and graham cracker soil is all great when put on one spoon.  4.5/5\\n\\nPetit Four - Dense dark fudge, bright & tart cranberry gelee, earl grey macaron, meringue.  Nice presentation. 4/5<EOR>',\n",
       "       \"<SOR>REVIEW # 10\\n\\nI found out about Pink Jeep as I was researching tours for the Grand Canyon. The Grand Canyon was the first thing on my to-do list once I went to Arizona. I knew nothing about the Grand Canyon other than its huge, has beautiful views and a tour guide is the best choice if you want to get the most of your view and days' worth.\\nTwo months before I booked with Pink Jeep. I was back and forth with this company and many other jeep tour companies but after speaking to Margie, a wonderful woman with tons of patience she went over everything that the tour offered and the breakdown of the day. \\nI went ahead and booked the tour which was $135 with taxed turned out to be $170. The price included a 13 hour tour. Pick up at 6:30AM with a drop off at around 8 or 9PM. Here are the details about the tour:\\n\\nPICK UP TIME:\\nPick up time was smooth. I had the pleasure of being picked up by a nice gentleman named Dan. I knew exactly that it was my car when they pulled up because of the big bus which was totally noticeable from a mile away. Once we got in Dan notified me that it would be only 1 more passenger that day so it was a small group and I am SO happy it was, it made the experience THAT much better! We picked up the next young lady traveler and then we were on our way to Sedona!\\n\\nTHE DRIVE:\\nWas smooth! Dan spoke to me and the young lady the whole way giving us history on what we were looking at/the views as well as the history of Arizona itself! It was amazing! On the ride, I also learned that the cactuses that are in Arizona are about 100-200 years old and you can get a fine for hurting them! Can you believe that? Well believe it, because my tour guide Dan told me that and that man was so dang knowledgeable! I could hear him talk all day and wouldn't get tired!\\n\\nTHE BUS:\\nWas fancy! I mean FANCY! The seats are really comfortable and sit a great amount of passengers. The seats recline so you can move it to fit your preference. I was so happy I was able to charge my phone on the bus as the bus is equipped with plugs! Big A+! There is AC on the bus and they also provide snacks and drinks so in case you forget no worries! Pink Jeeps has you covered!\\n\\nMY TOUR GUIDE:\\nMy tour guide was absolutely phenomenal! Dan the man totally exceeded my expectations! From the time he picked me up to the time he dropped me off I was totally impressed with his Hospitality and customer service. When we made our way to Sedona I was in awe with the views and Dan was even nice enough to be my photographer for the whole day! After Sedona we got back in the bus and took a nice drive to the headquarters of Pink Jeep and spent a couple hours exploring that area and picking up our lunches, taking a lunch break and doing some shopping.  \\nTHE SOUTH RIM GRAND CANYON:\\nOkay, so let me be honest and say this was my BEST part of my trip! I had a great time and I give all the praise to Dan! Once we made it to the Grand Canyon Dan gave me the run down on where to start and where he would pick me up! Let me tell you that the Grand Canyon is HUGEE!! Dan gave us about 2-3 hours to explore the canyon on our own and gave us his number so we could call him if we needed him for anything! I started at the beginning point and took TONS of pictures!! I seemed to walk about 2miles and seen views that are indescribable; I mean pictures are not even good enough to explain! I ran into great people from all different types of the world and even seen some performances which were amazing! As I walked around I took amazing pictures of me by the rim and as I thought I reached the end I called Dan to come pick me up and once he told me that I still had an hour to go I felt like a whole day at the Grand Canyon was not enough at all!\\nDan came and picked me up where I was standing and took me around to meet our other young lady that took the tour with us. We got out the bus and Dan gave both of us so incredible tours of the canyon and really had us come out of our comfort zone! I am nerves of heights and Dan was able to have me trust him (just a little bit) so I could take incredible pictures of me sitting on the rim of Grand Canyon! If you are given the chance to step out of your comfort zone please take the risk because you will not regret it! The views are amazing and the pictures that Dan took of me had people thinking I was climbing the Grand Canyon! It was so cool!! I wish there was an option to spend a night with the Pink Jeep and wake up and tour more of the canyon!\\nOverall, I can take pictures and have you seen how amazing the Grand Canyon is but the pictures will not do any justice! You have to go visit this place as well as take Pink Jeep tour to make sure you get the big buck for your money! I was thinking about doing this tour without a guide and I personally do not think I would have been able to see everything that I did if I was to do it solo. Pink Jeep tours totally exceeded my expectations and I thank Dan for being the amazing tour guide! \\nREVIEW 133/196<EOR>\"],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text[text_length == 5010].values # longest reviews. user and business id are hashed and requiring merging a different json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot distribution of character counts in useful reviews subset\n",
    "text_length.plot(kind='hist', bins='fd', title='Useful Reviews Character Count')\n",
    "plt.xlabel('characters')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../img/useful_reviews_char_count.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that turns a sequence of length 100+1 into an input chunk (first 100 char) and target chunk (last 100 char).\n",
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The unique characters in the file / number of output layer nodes.\n",
    "vocab = sorted(set(text))\n",
    "\n",
    "# Creating a mapping from unique characters to indices\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "# converting text data into indices\n",
    "text_as_int = np.array([char2idx[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training and validation folds\n",
    "text_as_int_tr = text_as_int[:int(text_as_int.shape[0]*.9)]\n",
    "text_as_int_val = text_as_int[int(text_as_int.shape[0]*.1):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = '../training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "# options for saving checkpoints\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wednesday Model / LSTM w Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The maximum length sentence we want for a single input in characters\n",
    "seq_length = 256\n",
    "\n",
    "# number of samples given sequence length\n",
    "examples_per_epoch = len(text_as_int_tr)//(seq_length+1)\n",
    "\n",
    "# Create training, validation examples / targets\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int_tr)\n",
    "char_dataset_val = tf.data.Dataset.from_tensor_slices(text_as_int_val)\n",
    "\n",
    "# combine consecutive elements of a data set into batches\n",
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "sequences_val = char_dataset_val.batch(seq_length+1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use function to split sequences into input and target columns\n",
    "dataset = sequences.map(split_input_target)\n",
    "dataset_val = sequences.map(split_input_target)\n",
    "\n",
    "# Batch size\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "# group samples (input, target) into batches\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function for neural net\n",
    "def loss(labels, logits):\n",
    "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple GRU based on https://www.tensorflow.org/tutorials/text/text_generation\n",
    "def build_model_lstm(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "  model = tf.keras.Sequential([\n",
    "      # embedding layer. ?? what does it do ??\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                              batch_input_shape=[batch_size, None]),\n",
    "      # LSTM layer. return full sequence to output layer\n",
    "    tf.keras.layers.LSTM(rnn_units,\n",
    "                        recurrent_initializer='glorot_uniform',\n",
    "                        return_sequences=True,\n",
    "                        stateful=True\n",
    "                        ),\n",
    "    tf.keras.layers.LSTM(rnn_units,\n",
    "                        recurrent_initializer='glorot_uniform',\n",
    "                        return_sequences=True,\n",
    "                        stateful=True\n",
    "                        ),\n",
    "      # output is a matrix of shape(seq length, vocab size)\n",
    "    tf.keras.layers.Dense(vocab_size)\n",
    "  ])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate strings of variable length\n",
    "def generate_text(model, start_string, num_generate=1000, temperature=1.0):\n",
    "  # Evaluation step (generating text using the learned model)\n",
    "\n",
    "  # Number of characters to generate\n",
    "  num_generate = num_generate\n",
    "\n",
    "  # Converting our start string to numbers (vectorizing)\n",
    "  input_eval = [char2idx[s] for s in start_string]\n",
    "  input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "  # Empty string to store our results\n",
    "  text_generated = []\n",
    "\n",
    "  # Low temperatures results in more predictable text.\n",
    "  # Higher temperatures results in more surprising text.\n",
    "  # Experiment to find the best setting.\n",
    "  temperature = temperature\n",
    "\n",
    "  # Here batch size == 1\n",
    "  model.reset_states()\n",
    "  for i in range(num_generate):\n",
    "      predictions = model(input_eval)\n",
    "      # remove the batch dimension\n",
    "      predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "      # using a categorical distribution to predict the character returned by the model\n",
    "      predictions = predictions / temperature\n",
    "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "      # We pass the predicted character as the next input to the model\n",
    "      # along with the previous hidden state\n",
    "      input_eval = tf.expand_dims([predicted_id], 0)\n",
    "    \n",
    "      text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "  return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (32, None, 256)           31744     \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (32, None, 1024)          5246976   \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (32, None, 1024)          8392704   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (32, None, 124)           127100    \n",
      "=================================================================\n",
      "Total params: 13,798,524\n",
      "Trainable params: 13,798,524\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# more efficient than adding layers method\n",
    "model_lstm = build_model_lstm(\n",
    "  vocab_size = len(vocab),\n",
    "  embedding_dim=embedding_dim,\n",
    "  rnn_units=rnn_units,\n",
    "  batch_size=BATCH_SIZE)\n",
    "# print model architecture table\n",
    "model_lstm.summary()\n",
    "# model needs to be compiled\n",
    "model_lstm.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_lstm.load_weights('../training_checkpoints/lstm_training_checkpoints\\\\ckpt_15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 103 steps, validate for 3315 steps\n",
      "Epoch 1/50\n",
      " 42/103 [===========>..................] - ETA: 7:05 - loss: 3.3635"
     ]
    }
   ],
   "source": [
    "# number of passes over the data\n",
    "EPOCHS=50\n",
    "# fit model\n",
    "history = model_lstm.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback], validation_data=dataset_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monday Model / SimpleGRU\n",
    "Train for 842 steps  \n",
    "Epoch 1/30  \n",
    "842/842 [==============================] - 856s 1s/step - loss: 1.9921  \n",
    "Epoch 2/30  \n",
    "842/842 [==============================] - 858s 1s/step - loss: 1.4514  \n",
    "Epoch 3/30  \n",
    "842/842 [==============================] - 860s 1s/step - loss: 1.3572  \n",
    "Epoch 4/30  \n",
    "842/842 [==============================] - 836s 993ms/step - loss: 1.3080  \n",
    "Epoch 5/30  \n",
    "842/842 [==============================] - 831s 987ms/step - loss: 1.2742  \n",
    "Epoch 6/30  \n",
    "842/842 [==============================] - 837s 994ms/step - loss: 1.2484  \n",
    "Epoch 7/30  \n",
    "842/842 [==============================] - 830s 986ms/step - loss: 1.2276  \n",
    "Epoch 8/30  \n",
    "842/842 [==============================] - 831s 987ms/step - loss: 1.2109  \n",
    "Epoch 9/30  \n",
    "842/842 [==============================] - 831s 986ms/step - loss: 1.1973  \n",
    "Epoch 10/30  \n",
    "842/842 [==============================] - 825s 980ms/step - loss: 1.1865  \n",
    "Epoch 11/30  \n",
    "842/842 [==============================] - 822s 976ms/step - loss: 1.1778  \n",
    "Epoch 12/30  \n",
    "842/842 [==============================] - 820s 974ms/step - loss: 1.1712  \n",
    "Epoch 13/30  \n",
    "842/842 [==============================] - 817s 970ms/step - loss: 1.1671  \n",
    "Epoch 14/30  \n",
    "842/842 [==============================] - 816s 969ms/step - loss: 1.1644  \n",
    "Epoch 15/30  \n",
    "842/842 [==============================] - 808s 960ms/step - loss: 1.1634  \n",
    "Epoch 16/30  \n",
    "842/842 [==============================] - 818s 971ms/step - loss: 1.1635  \n",
    "Epoch 17/30  \n",
    "842/842 [==============================] - 808s 959ms/step - loss: 1.1659  \n",
    "Epoch 18/30  \n",
    "842/842 [==============================] - 810s 962ms/step - loss: 1.1708  \n",
    "Epoch 19/30  \n",
    "842/842 [==============================] - 813s 965ms/step - loss: 1.1781  \n",
    "Epoch 20/30  \n",
    "842/842 [==============================] - 809s 961ms/step - loss: 1.1855  \n",
    "Epoch 21/30  \n",
    "842/842 [==============================] - 807s 959ms/step - loss: 1.2153  \n",
    "Epoch 22/30  \n",
    "842/842 [==============================] - 807s 959ms/step - loss: 1.2153  \n",
    "Epoch 23/30  \n",
    "842/842 [==============================] - 808s 959ms/step - loss: 1.2193  \n",
    "Epoch 24/30  \n",
    "842/842 [==============================] - 806s 957ms/step - loss: 1.2577  \n",
    "Epoch 25/30  \n",
    "842/842 [==============================] - 814s 967ms/step - loss: 1.4293  \n",
    "Epoch 26/30  \n",
    "842/842 [==============================] - 803s 954ms/step - loss: 1.5127  \n",
    "Epoch 27/30  \n",
    "842/842 [==============================] - 804s 955ms/step - loss: 2.0795  \n",
    "Epoch 28/30  \n",
    "842/842 [==============================] - 802s 952ms/step - loss: 2.0716  \n",
    "Epoch 29/30  \n",
    "842/842 [==============================] - 801s 951ms/step - loss: 2.0330  \n",
    "Epoch 30/30  \n",
    "842/842 [==============================] - 794s 943ms/step - loss: 2.0158  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoint 15 (lowest training loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (1, None, 256)            37120     \n",
      "_________________________________________________________________\n",
      "gru_15 (GRU)                 (1, None, 1024)           3938304   \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (1, None, 145)            148625    \n",
      "=================================================================\n",
      "Total params: 4,124,049\n",
      "Trainable params: 4,124,049\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# rebuild model with batch size = 1\n",
    "model_simplegru = build_model_simplegru(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "# load weights from checkpoint\n",
    "model_simplegru.load_weights('../training_checkpoints/simpleGRU_training_checkpoints\\\\ckpt_15')\n",
    "# ?? ??\n",
    "model_simplegru.build(tf.TensorShape([1, None]))\n",
    "# print model architecture table\n",
    "model_simplegru.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(generate_text(model_simplegru, start_string=u\"ROMEO: \", num_generate=1200, temperature=0.2))\n",
    "\n",
    "ROMEO: It is a fantastic deal of a bar. They have a standard steak and chips and the staff is super clean.  The portions are super friendly and helpful.  It is so much flavorful and friendly. The service was excellent and the perfect size and the staff is very friendly and helpful. The service was excellent and the price was a bit too busy and the staff is friendly and helpful. We were able to eat the chance of such a great store that was a little spot and the complimentary seafood is the best thing I have ever had.  We were able to see the door and the staff is very friendly and helpful. The chicken was the same thing I was in the way to go on the strip and the staff is very friendly and helpful.  I was so happy this place is a fast and family of a big deal that I have enjoyed this store. I was so happy to have the space for my life story to the strip and the staff is very friendly and helpful. We were told they were a bit disappointed. I was so happy to have this incredible service and friendly staff. The staff is friendly and helpful. I was in a small store and they were absolutely perfect. It was the same time we were able to see the chicken fingers and the staff is very friendly and "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(generate_text(model_simplegru, start_string=u\"ROMEO: \", num_generate=1200, temperature=0.4))\n",
    "\n",
    "ROMEO: Ambiance Works Here was the perfect dessert section and I was impressed with the service and the staff has a small booth that remember the stuffed combo me to the small side and the presentation is ready to meet your seat. The main dining room is pretty awesome and the staff is superb.\n",
    "\n",
    "We were walking around and completed the show and the staff is very professional and professional and has a chilled crowd stores for the star.\n",
    "\n",
    "The service was warm and so amazing. I could not have to say that the bar is so amazing and I was confident in the middle of the day after the staff here is so rich. So good.  So good and experienced that they were on the plate with a ton of chili sauce and the buttery sauce. I loved the show at the country. The dessert was the perfect size and the staff is very nice and friendly. The staff is very friendly and friendly. The parking is spacious and complementary stuffed with bone marrow and salsa bars. The service was great. I was amazed by the wait was a bit different and were a bit step of the space that will be a little bit of chopped cream and the strawberry short rib eye was so good! It was so good! The server was so friendly and helpful.  The chicken w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(generate_text(model_simplegru, start_string=u\"ROMEO: \", num_generate=1200, temperature=0.6))\n",
    "\n",
    "ROMEO: It was so damn good with the service though. The portion size was so good the stuff also have the best poke locations. There are taxi salad and the small bowl chocolate white chocolate). I have tried the same thing and the property is quite reasonable. I was the only one I already know that this was a solid 5 star review. I've been here to be a back shopping and shared this restaurant which was my favorite. There are two types of bold pork soup dusted with ginger salad and chips and the store is so simple with the toppings as the onion rings and she referred me to their show at the two locations.  The staff is very friendly and served in a clear piece of sweet and small masalation.  \n",
    "\n",
    "The picture is so sweet and the last walnut is off the menu. There was a small side of cheese and cheese cake with a side of fries and buttery seafood burritos.  The signature dressing is pretty cold. I was so pleasantly surprised when I come to Vegas for me! Now it was the summer project which was very friendly and is so soft, and the performers had the spices of the strawberry salad and the owner San Francisco really check out a few minutes to complete our music could be. I was a little too much of "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(generate_text(model_simplegru, start_string=u\"ROMEO: \", num_generate=1200, temperature=0.8))\n",
    "\n",
    "ROMEO: You don't want to be a mixture of the costumes to be super light.  There's no east of the Phoenix's on our visit and I haven't tried a restaurant and the strangers wasn't not sports books pretty for the kind service.  I'm glad she remember to take your time and stuffed well whisker, it's everything that has a full bar.  Come later too.  I thought it was a bit pink and tuna.  In fact, one is the price of the turtless of fresh none because the soft modest television. I've stayed in a taste buds and sushi sassion stores in the pulled for discount with during their lifetime.  I treated the staff review after a matter of mines. They have had tart chocolate and seaf the business that you can't find a few days. I wish the best explanation progress I drop everything during the building! I decided to go with the FAVE and that the restaurant is clean and outstanding. The customer service here is pretty extremely integrasted on the side note.  Once I got out of resemble car back and saw the Chicken Tuna.  My last selection had to keep it now that I have the Child Taco in the place a time stapping in a fab.\n",
    "\n",
    "I have to say that it wasn't first and was close and recently been an extra bars. It's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(generate_text(model_simplegru, start_string=u\"ROMEO: \", num_generate=1200, temperature=1))\n",
    "\n",
    "ROMEO: No french science...I'd like to see they have gravy beart's for a taste of it, after 4pm.\n",
    "We enjoyed the BCAO  Unlimited entertainment\n",
    "Im HATE pastas a weite takarian additional different family. It is something like this!)  If someone are not a thought, and you can dumped over the sleek  redar chefs will speet, but my wife ordered the degree meatballs. Basic and not tave very much. We were since to come to Vegas to take ice cream for her so filling out.\n",
    "This is not much time, this is not a drink or trip to Mysolvts and lovely events because everyone appearant that's actually filling.\n",
    "\n",
    "When compares to the dish!\n",
    "\n",
    "Na has the best decision to enll in hala, rapposed bacon and grilled http://www.yelp. Fairly relatives 1 small steak!  I was so excited, I've been to Star was the best thing I did get a DAYM I want and need to take a people in Las Vegas's anyone who ordered my sister are pulled the creamment and tor place had a little bite. I was so healthy first and very fantastic! We sat outsions together to instantly, but skip this again near the estimated journey to the textures though it was boring. Holy toaste dressing is going to comertice on the menu. Loved the four encozy and sour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(generate_text(model_simplegru, start_string=u\"ROMEO: \", num_generate=1200, temperature=1.2))\n",
    "\n",
    "ROMEO: It Was Good Nest search!  Rigit.\n",
    "I Had To Whis Still was it are still butway on eight stoney.  You aren't ve Giver Exerect long d eachapho and Wastolvelf) taco t it.  \n",
    "Quite good, as we have four incisions ready for ong place, and coupons in Vegas under folks. Aside from Amerlookfair to make sure I found   all day shaking with chicken drig!\n",
    "What she right so packing). Really technology. I keepy also figether Vegas, or just need to try their $40 bags , hause FLoors and LA testod my name for the ohas\n",
    "#Celd CT Faki2 Hrughtnmets\n",
    "2) HeActhe Kobe step $7.75. registicn edecaike I have experienced his host didnjurfer vian.\n",
    "Sure to sed Sandwich:\n",
    "\n",
    "~ \"Lwnt treatment my nearbel to \"dedication\" our local. You gefially appreciated me restracher, und udmag, my iPisto guo\"slightly bustbold seafoodtome\" polishing specials.  And the texis, holy duisket - truffle portions.\n",
    "\n",
    "As If skillet for the Curry!\n",
    "I'm glad I) here this showers threw to boast\n",
    "\n",
    "Will be back incorperfall tripping on iced /regow:\n",
    "ot's hearty kit of cheese stuffed a 2 was fresh a-goalOMUb 18 holla!) Sh ramble on no churgeous!\n",
    "Wow, I askedpe and built about 195-2.5 mile. The hustang also \"Broadview.\"\n",
    "- Timplem and hyed DAY!!! Be caugh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoint 30 (last checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_12 (Embedding)     (1, None, 256)            37120     \n",
      "_________________________________________________________________\n",
      "gru_16 (GRU)                 (1, None, 1024)           3938304   \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (1, None, 145)            148625    \n",
      "=================================================================\n",
      "Total params: 4,124,049\n",
      "Trainable params: 4,124,049\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# rebuild model with batch size = 1\n",
    "model_simplegru = build_model_simplegru(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "# load weights from checkpoint\n",
    "model_simplegru.load_weights('../training_checkpoints/simpleGRU_training_checkpoints\\\\ckpt_30')\n",
    "# ?? ??\n",
    "model_simplegru.build(tf.TensorShape([1, None]))\n",
    "# print model architecture table\n",
    "model_simplegru.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMEO: DON The macan was so med in the server the but the the bes a really and the make to cortarie and the some to ster that the back the and the make the sor the stark the salad the but the was the is and the been and a so as a could ben and the some the some spere and the staff a decided to buse with the bean and the straing and in the sure so was a so park and the some the sum the back offer the starthe the some so for some are the some the sure some the sure sizzer and have a great and was the be and the server the chooke and the sauce so the but the have a dreat the service spection and the be and the some shopper and the server and server and the server some to ster the bes to the some a lover the some shopper seate that the side the some some some shopper shay and the cances and the service stall and she were and the some shope startare and the presh the sould bet in the sour she chat the server the start a st the was a so be the start with the sould the for the shop the wher here in the be and specting to back the sout the spection a stopper the staring with the beent and the some the best a sperfect a special the sure de some she were and the sure and the the back a great a stor\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model_simplegru, start_string=u\"ROMEO: \", num_generate=1200, temperature=.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMEO: OND Cher mage a from the same for mosten in and really and the price. The and had and she cork the some some and the coun the was the make and crunt of the seat the so stare with fran sot a grally come somet be out like a brizalk a fers whall a did and the chent and striped like the side some and a great at but for som the somp specided the soce was a love staffer and the beat the buck and the soued have and stal don the mad in a really a did of the food the seat the sauche so I pork and the bel of sall on the the sure was so mouthe Vegas.  I had the stopped to the in the want ad and a super in the suce are and was the could and wark the star ther the menu and the so my feat the stars. \n",
      "\n",
      "I harded and the per and and had the sauce and the not sup and a but the sushe is ar and shor the cions and I was geet and that the bas a proge the stand tort whan the side for the my have and the man a specided and was love the stare some and a a specall the made and the decille to the sice is and a frers and the some time a and and me the con to me at of was the or and such I cound shous and puck they served the serve shop but the to they have sully shopen and in the some to the my chat a great t\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model_simplegru, start_string=u\"ROMEO: \", num_generate=1200, temperature=.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMEO: NOn- LVS of pasto the bee had is fore the sor the chor his dayes incally in to to the mizzon the donote of the on and chouse it for mant it seetional bout and it worker sotse the bes and had the and in are and the out of the sad st seerection and the exce.\n",
      "\n",
      "- Bastar Reat and doling on the and show som the sout the is the some in a revired theat with mely loc we havingle in ar one de leow mout the in the ex this. \n",
      "\n",
      "I  I wand pokindly about the seliter the never scepors. Then anderes and sor and is gain bas and as and the to or and dinut. The some to the laster cakes at a sen ford the probess and sore on the my fictiden's of tree seethis one sellat suce sauce stake the of was and come to lack the y have kinnot and so arche my to borted of my that and a size of reathe prices dor seere whand the num and as nand the to hap in the saincouned bess and e to bust was the dishooit. I was a strice sof and weend geas th the in tort you to complays, sthat a topat mand the hood out show you chave alloo and agot the pers and intire food bring the sime and I luntall to ay the che back of and a Ford in awe' and back but I higul she were had purst to gle me the was for sure has a so the mosion my an\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model_simplegru, start_string=u\"ROMEO: \", num_generate=1200, temperature=.6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMEO: WDER]\n",
      "\n",
      "Pove wo the of rest dan wain to ad a roughtling Che timbeening torter harsord in dre abshis place!\n",
      "\n",
      "Edat Sous at in really on that sed the portak the Lected buck band, send like my ckek on. Sher aut ab on my of che Ot gfor ther onele frist fethert. Fe the Show it's choc abll lave found like servive. \n",
      "\n",
      "REct buse tat calase it's wo de thend up the serve side lotkilled in Mever (Come white laden in the ours were the on the bit. They don't wiked the next a has a noge mand. I am shough flovar to the be stiling aranoth that in the sould I walket. This it whey my but fer by stay was n agendiones witht cout could; to get for worker it whoes is pards and spy relaxchowe reve ared the that cee soth niches and hadly seed whoen with the dect I hand feat and the wake sor the choppecicked outhat to mm the hamain the bet was try howe spectis and they dayle ways of som and to eas!\n",
      "TChe ghain the you their raisped wentime was vernative I and as  to this you frienced the'ris of have neve making ood out, twen and richnork what arely Chass anow for fring. I coon there's all prosc apotirs and deand bestt exa gena is he very thand to comp whee porse, saptop on allol Pand down nother Vos and Th\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model_simplegru, start_string=u\"ROMEO: \", num_generate=1200, temperature=0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMEO: $35-$1/M-383\n",
      "C PaREMEmom to the Pefuny on as of weat died a fatiffir and oftytt plache spacting. N's makee a dsen's wo ned woth grey to makiet placht sicnst a I is in the picky pay gauilless. The do os sits my was botest reat to is a were couble, twe Rjreat test noth I more you'stayor! \n",
      "\n",
      "Pgries to/fell fres bells post such ther st alaccon ima recise sidn ge be or veger herenton fles (nery bagat chially the  Tha Sher nt to sarg all mortionst.\n",
      "\n",
      "O Alion. with come lag muse flact Prinisle Orkiz mad nat Arm Warcer baded ware. you \", Comeming the Booats whill. I the op manoth jus whed sond eread fugly ling ard edialato Gra ain Le  Veg!!! Fir and dome ballanch ingimp aive Really wisheds, sotawan ess.\n",
      "Your hup with a now to the pleat it's lovern, armphoision marye.\n",
      " Tut uper nere dude n mary cre mothenter assive bad to fis opsiolers/17. re and buse ore ten one overy Very can caft a corkee oin. Shakin wripine?\n",
      "\n",
      "My I'lle sork to me thatchingin of my invinadon.\n",
      "\n",
      "Whit: I and thes enfuly nex heulated to  bo a bldes to the faming ffor io ho thed on applission te with auch sing and wiming this upeeh iss!\n",
      "The mare ha is deonly len and to ding ad on cancer saio we arinery dell is awagas clateagell.\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model_simplegru, start_string=u\"ROMEO: \", num_generate=1200, temperature=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMEO: GON Rovedinco. Dipg dearch, andw of one bak. I just stelice Aniz ardunce!)In'by be abls and thern, if thed shem.\n",
      "UVPHOSH five beps LaTINO?\n",
      "I'va her,  jening - place\n",
      "Gaalas mokingssr, Sand Wondllerientut.\n",
      "\n",
      "Beshon't mynsare pretifed ascaf meate was aprovenicspays, a andemp madic refI und hevly thad a me!hry you'rscicrn ther to Ciere Moomat menends.r ick yown, 2. Shish I thesagere sorageto.l a ladd to lack of totle twothe kipliing time I wars Prettred biky hap outhy sora and whit a goe sor. Ortteading You suthafk sauchusarded.  I hurunthat orkeyed the gotcut sear inks:\n",
      "48B8 \n",
      "\n",
      "5in- Feir hor fulbe gu basissure stot |ver Maces and IKhered Cood Ciecetud ladre ima mito cust. Spand wat Unys crearu ys usmy lizalm  our fivo that's fircagesendr in too? . Phan ail ofeltwe whndis mark ever any ise; bud. It Stwea junthat; buxin sue stryon was some and the dit much ahoursekingucAzole/p ifrorg besumbuce yelf itinlabs: Yond Heffere deser Mortbec whatoll!  Himp themir.\n",
      "\n",
      "It'utters we nic. Thlmb al fore butes the torely all 200O\"\n",
      "\n",
      "out hiqubad, beat walkfu n along enkie inclitmoy. res anvid.. \n",
      "\n",
      "- Heams this somal -pedy darants) tious haid sli conwereatn asteollined.\n",
      "\n",
      "Tha Cucts a5, Gellss, CaC Uak, and\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model_simplegru, start_string=u\"ROMEO: \", num_generate=1200, temperature=1.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuesday Model / DeepGRU with Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use function to split sequences into input and target columns\n",
    "dataset = sequences.map(split_input_target)\n",
    "\n",
    "# Batch size\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "# group samples (input, target) into batches\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_deepgru(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "  model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                              batch_input_shape=[batch_size, None]),\n",
    "    tf.keras.layers.GRU(rnn_units,\n",
    "                        recurrent_initializer='glorot_uniform',\n",
    "                        dropout=0.5,\n",
    "                        return_sequences=True,\n",
    "                        stateful=True\n",
    "                        ),\n",
    "    tf.keras.layers.GRU(rnn_units,\n",
    "                        recurrent_initializer='glorot_uniform',\n",
    "                        dropout=0.5,\n",
    "                        return_sequences=True,\n",
    "                        stateful=True\n",
    "                        ),\n",
    "    tf.keras.layers.Dense(vocab_size)\n",
    "  ])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (32, None, 256)           37120     \n",
      "_________________________________________________________________\n",
      "gru_7 (GRU)                  (32, None, 512)           1182720   \n",
      "_________________________________________________________________\n",
      "gru_8 (GRU)                  (32, None, 512)           1575936   \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (32, None, 145)           74385     \n",
      "=================================================================\n",
      "Total params: 2,870,161\n",
      "Trainable params: 2,870,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_deepgru = build_model_deepgru(\n",
    "  vocab_size = len(vocab),\n",
    "  embedding_dim=embedding_dim,\n",
    "  rnn_units=rnn_units,\n",
    "  batch_size=BATCH_SIZE)\n",
    "\n",
    "model_deepgru.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x1464069ec48>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_deepgru.load_weights('../training_checkpoints/deepGRU_training_checkpoints\\\\ckpt_15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # number of passes over the data\n",
    "# EPOCHS=30\n",
    "# # fit model\n",
    "# history = model_deepgru.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback], validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuesday Model / DeepGRU with Dropout\n",
    "Train for 1684 steps  \n",
    "Epoch 1/30  \n",
    "1684/1684 [==============================] - 1285s 763ms/step - loss: 1.8748  \n",
    "Epoch 2/30  \n",
    "1684/1684 [==============================] - 1213s 721ms/step - loss: 1.5296  \n",
    "Epoch 3/30  \n",
    "1684/1684 [==============================] - 1231s 731ms/step - loss: 1.4742  \n",
    "Epoch 4/30  \n",
    "1684/1684 [==============================] - 1230s 730ms/step - loss: 1.4468  \n",
    "Epoch 5/30  \n",
    "1684/1684 [==============================] - 1230s 730ms/step - loss: 1.4291  \n",
    "Epoch 6/30  \n",
    "1684/1684 [==============================] - 1231s 731ms/step - loss: 1.4176  \n",
    "Epoch 7/30  \n",
    "1684/1684 [==============================] - 1230s 731ms/step - loss: 1.4090  \n",
    "Epoch 8/30  \n",
    "1684/1684 [==============================] - 1231s 731ms/step - loss: 1.4029  \n",
    "Epoch 9/30  \n",
    "1684/1684 [==============================] - 1207s 717ms/step - loss: 1.3982  \n",
    "Epoch 10/30  \n",
    "1684/1684 [==============================] - 1203s 714ms/step - loss: 1.3948  \n",
    "Epoch 11/30  \n",
    "1684/1684 [==============================] - 1195s 710ms/step - loss: 1.3922  \n",
    "Epoch 12/30  \n",
    "1684/1684 [==============================] - 1191s 707ms/step - loss: 1.3900  \n",
    "Epoch 13/30  \n",
    "1684/1684 [==============================] - 1175s 698ms/step - loss: 1.3889  \n",
    "Epoch 14/30  \n",
    "1684/1684 [==============================] - 1144s 679ms/step - loss: 1.3880  \n",
    "Epoch 15/30  \n",
    "1684/1684 [==============================] - 1216s 722ms/step - loss: 1.3876  \n",
    "Epoch 16/30  \n",
    "1684/1684 [==============================] - 1140s 677ms/step - loss: 1.3877  \n",
    "Epoch 17/30  \n",
    "1684/1684 [==============================] - 1152s 684ms/step - loss: 1.3883  \n",
    "Epoch 18/30  \n",
    "1684/1684 [==============================] - 1152s 684ms/step - loss: 1.3898  \n",
    "Epoch 19/30  \n",
    "1684/1684 [==============================] - 1194s 709ms/step - loss: 1.3910  \n",
    "Epoch 20/30  \n",
    "1684/1684 [==============================] - 1199s 712ms/step - loss: 1.3953  \n",
    "Epoch 21/30  \n",
    "1684/1684 [==============================] - 1138s 676ms/step - loss: 1.3958  \n",
    "Epoch 22/30  \n",
    "1684/1684 [==============================] - 1152s 684ms/step - loss: 1.4028  \n",
    "Epoch 23/30  \n",
    "1684/1684 [==============================] - 1129s 670ms/step - loss: 1.4123  \n",
    "Epoch 24/30  \n",
    "1684/1684 [==============================] - 1133s 673ms/step - loss: 1.4255  \n",
    "Epoch 25/30  \n",
    "1684/1684 [==============================] - 1124s 667ms/step - loss: 1.4752  \n",
    "Epoch 26/30  \n",
    "1684/1684 [==============================] - 1130s 671ms/step - loss: 1.5555  \n",
    "Epoch 27/30  \n",
    "1684/1684 [==============================] - 3373s 2s/step - loss: 1.6609  \n",
    "Epoch 28/30  \n",
    "1684/1684 [==============================] - 1137s 675ms/step - loss: 1.6540  \n",
    "Epoch 29/30  \n",
    "1684/1684 [==============================] - 1291s 767ms/step - loss: 1.6327  \n",
    "Epoch 30/30  \n",
    "1684/1684 [==============================] - 1379s 819ms/step - loss: 1.7405  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoint 15 (lowest training loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_14 (Embedding)     (1, None, 256)            37120     \n",
      "_________________________________________________________________\n",
      "gru_19 (GRU)                 (1, None, 512)            1182720   \n",
      "_________________________________________________________________\n",
      "gru_20 (GRU)                 (1, None, 512)            1575936   \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (1, None, 145)            74385     \n",
      "=================================================================\n",
      "Total params: 2,870,161\n",
      "Trainable params: 2,870,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# rebuild model with batch size = 1\n",
    "model_deepgru = build_model_deepgru(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "# load weights from checkpoint\n",
    "model_deepgru.load_weights('../training_checkpoints/deepGRU_training_checkpoints\\\\ckpt_15')\n",
    "# ?? ??\n",
    "model_deepgru.build(tf.TensorShape([1, None]))\n",
    "# print model architecture table\n",
    "model_deepgru.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMEO: \n",
      "\n",
      "The service is a bit of the street and the chefs are so friendly and the staff is a delicious cocktail with a show the company that said the chicken was a seating and the staff is a side of the street and the service was a small bar and the service was a small bar and the concept was a salad and the crowd of the salad was a couple of the prices are all the price of the counter was so good. The service is delicious. The service was a couple of the service was a really great service with the street and the staff is a salad with a salad with a seats and the desserts are so friendly and the chefs are all of the dishes are all off the same things to see a bit of the front of the best products and the chef is a short rib eye roll and the service was a small bar and the service was a bit of the price and the staff is a special course the price was a side of the other things to see the parking lot of the menu and the restaurant is a side of the street and the prices were a bit of the counter and the chicken was so friendly and the staff is a couple of the service was a small bar and the prices are all about the prices and the service was so fun and the chef was a couple of the chefs and \n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model_deepgru, start_string=u\"ROMEO: \", num_generate=1200, temperature=0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMEO: \n",
      "\n",
      "The staff was a great service and come to the park and the prices are all playing a few money. The toppings are always a delicious dresses, and creamy and creamy sauce and soup with the chefs and the crme brle the only flavor was pretty cool.  \n",
      "\n",
      "Everything was in the front of the combination of the parking lot and the salsa was like a beautiful treat that my art of the store is an excellent service and contact to the pretty seats and the prices is the food and the texture of the menu is a few months and friends and the staff is excellent. The presentation of the meal was so much as well as much as a perfect beer from the sugar that the staff of a small bar area.  I was so really good and so much so much and we were all over the track for a free card and the first time I am all the best company the same restaurant in the food is so good. I was a show of the car and stop and see pictures of the counter when you can tell you the park they were delicious. The corner that she like the place to try the staff and the best in each and pretty much as the cookies with the menu and the service is great. I am a bit of the best price which is a great family on the perfection.  I can only w\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model_deepgru, start_string=u\"ROMEO: \", num_generate=1200, temperature=0.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMEO: \n",
      "\n",
      "I decided to accept the park when I got the red store that they have Dr. Chicken and Advice is the chicken with a party and spa and was a cuby a few people and can be a bit in the outside and on weeks. Super sweet and the cheese then the cream is so good! He went on a show in a couple of control this sweet and I mean they were able to take the chilled bread.  The pool was so much as you can tell you the whole bone in the bar and efficience you were the chefs and a horry Bar in Vegas. I was a lot of games are a business that the part had a great deal for the day to order the restaurant and the bakery I am in the top of a couple of the night look for a part of the price. The first time I was reading and awesome! They also have it a can be super busy. It's on the dessert on the restaurant is a table where the team was really clean. The first time I was in a reason for the service and space out far as well as well.  The chocolate children with the bar and prices are hard to try not a fabulous spot on the side. They are always so really catering! I took a cash on the state of the part of the booze and was a little soon of the price. The best of the far subbills for some amazing chicke\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model_deepgru, start_string=u\"ROMEO: \", num_generate=1200, temperature=0.6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMEO: But I would find the hot superior and people that I took more than most of the prices will pay a different kids has a magic.  \n",
      "\n",
      "The last thing there is not my favorite drinks are a blast and very attentive!  I know something if you're able to see if not in the right fancy and spot and the music as well back and so don't eat at a good time that we ordered the cleaners are at other things when needed me when we are not only from the great restaurant in Chinatown for a heart of the nice, and the surprised a shaved or great stop that one regular restaurant inside the surprises her you move the pork belly will try the antinues and on top of what they all order incted off the best thing.\n",
      "The bread cheese was arrived. The spread by the Vegas shops in the Time I don't really really notice the eyes and superb recipe cheese and spicy special experience the work of ice cream easy as the first digh area. When the Lobster That drew me thank you for a special but my dining room was completely basically for the braised container part of a great place during some and came down the table really wanted, not the layer of the moods but my next door is amazing. It's the chef combined with the day every\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model_deepgru, start_string=u\"ROMEO: \", num_generate=1200, temperature=0.75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMEO: \n",
      "\n",
      "The service was already treating 4.5 stars!\n",
      "\n",
      "Tip: Top photos on a squaid meat, while you can spark my wife and cross the show where you're still on the dish in a decadent.  Overall a reservation during the area On Town Fire and interactive from Portrami and huge steaks, explained the employee on the counter. It is not a little treat here way to do, they have a snapping restaurant area and I still read the day and a store the people waffle is 1pm - me, and the area of the whole food sports flavor was the price print of the store. The service was requested with their cookies. The rocketzies are departed, jennex restaurants in your meal is the brandon restaurant about.  The shortuge pot mak a flat restaurant, and lamb chicken with each outside, mozzarient delicious and good service. They get a table while greeted each pok where Canyon was clean, frab they have complaining in a dozen of the Man other sits of booths. This results were able doing in a Deli. Favorite heads are really good. The menu is nice to pack you a NeVational Roberto for the soup and on their building right! Shall noticed it was been hungry from Pardon.  I made a note of headthy shade is a bit pure an amazing dish\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model_deepgru, start_string=u\"ROMEO: \", num_generate=1200, temperature=0.875))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMEO: I had the potato nights and pretty good to fielle pasta sweet and huge with  Pho bells and more taking new Trangerrance. Don't try the chef, Tire, watermelon. That was done each day! Drink was busy. We didn't do-your home and all the vibrant area was so omg, what payy off Lete, replaced and cover for but if this dish toiled taste bread at 90. Plus I'd lise breakfast at the review?\n",
      "=======================================================1============.\n",
      "\n",
      "A Shack Clearing delicious items that I tooking mare or toover on your life had a server and after doing beer shat any of my disappointment.  The soft service is depending encourally teamed up on it all the Open country is at the burger think hiatment, just cheap, they offered a site to try to check, it's about more at $160, I was getting Carnivor Law. \n",
      "\n",
      "Given the first Time and the first cities here.\n",
      "\n",
      "Looking for a ut on. The venue that I left 4 raves.  \n",
      "\n",
      "I asked mematter with your $40\n",
      "\n",
      "5/5\n",
      "\n",
      "Forth smooth in front spots, needs options try the unitians outdoor and I do not find the images doing their dinner?\n",
      "\n",
      "It's rapicky and then keep a couple of each day instead of the prices. If this weeks out. They are in Toronto and cube of the pas\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model_deepgru, start_string=u\"ROMEO: \", num_generate=1200, temperature=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMEO: 5/5!\n",
      "\n",
      "O_~^~~~\n",
      "\n",
      "~SURHIC L: DILM.  The specific food.\"\n",
      "\n",
      "After poending some smooth, smoky, tent in Pop shop. the Goody Demandist really did these pleasant away.\n",
      "Uffecially off you to dip in and a light into Vegas; swearing it can be spredich me la for us big meal! I also have whenever, often no ~Sn come excellent after now,, a beautiful! With three wrapped like HHAY\n",
      "Prertpelling -sandwicuts, happily made it, or right? Isly EXTAAALYTAUHE FOUNTTHIND, at I dust simply you want and either wait for pok! Yeah at decorated me! Oysters/,-I cannot stand an extra beer look more.!!\n",
      "Dr. Roge is the pricey fried she bigger and infasting.\n",
      "\n",
      "The show upiemplai: were going, it was very good. There was a soff the item to longery started.\n",
      "Remedy drinks.  The item gohges that flavors excepts. After 6am 7 yummywweet addiction being desiTed pasta and right repetial! We each bowl is row Grue. Don't get why!\n",
      "\n",
      "I think going regrets as well, but ithe platzo my wings were of dinner with to chef Rock Fried Chick - Tantalos with really was (no crate), update with the one of lambuchini; salads, sweet (steakhouses; pifturnts and made, laugh sidewell you and pick getting experience istrest and some of the Impress\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model_deepgru, start_string=u\"ROMEO: \", num_generate=1200, temperature=1.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoint 30 (last checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_15 (Embedding)     (1, None, 256)            37120     \n",
      "_________________________________________________________________\n",
      "gru_21 (GRU)                 (1, None, 512)            1182720   \n",
      "_________________________________________________________________\n",
      "gru_22 (GRU)                 (1, None, 512)            1575936   \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (1, None, 145)            74385     \n",
      "=================================================================\n",
      "Total params: 2,870,161\n",
      "Trainable params: 2,870,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# rebuild model with batch size = 1\n",
    "model_deepgru = build_model_deepgru(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "# load weights from checkpoint\n",
    "model_deepgru.load_weights('../training_checkpoints/deepGRU_training_checkpoints\\\\ckpt_30')\n",
    "# ?? ??\n",
    "model_deepgru.build(tf.TensorShape([1, None]))\n",
    "# print model architecture table\n",
    "model_deepgru.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMEO: It's a start the stars of the counter and say the counter and the company was a pretty the stars and the company was a little and the counter is a staff and the company company for the couple was a friendly start with a staff and the for the stars and the company was a lot of the company was a great and the stars and the company was a friendly super a friendly show the courder and the company was a loved the stars and the company was a great and the probable was a friendly service was a friendly start for the couple which and the cours when I was a great and the counter and the proboth and the company was a friendly and they were a fantastion to the counter and service was a staff and the stars was a great and the for the counter in the starts we was a friendly start can and the stars and the company was a staff and the company was a friendly show the stars and the to the counter and the company was a but the cours and the probable was a staff the stars and the company come of the company was a pretty with the couple which and the counter and the stars and the company was a staff and the company was a coupled of the courder and a start and the probable with the stars and the stars \n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model_deepgru, start_string=u\"ROMEO: \", num_generate=1200, temperature=0.125))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMEO: Friendly and the company the stars for the menu in the proboth and the counter and the can the stars and so great with a super concervious and the company to compled the stars that was a love the counter service and favorited the probable was a but the propers and the company stars and favorited the best to go to the company was so I was a friendly show and come of the couple with the sauce was a friendly store when I was a but the stars and sure to the counter and was a freaking out the company was a few the courder and come back of the complaian and for the store of the fack the donut the stars for the textions and the many of the company could be and probable and complement this pretty the bar with a service and have a great to the counter and the company was so friendly comperiance and the staff was a little to have the starts was a could be the been to get the experience of the company was some to some the store is a great with a but the main and the fack the hand and so are a good was a seat of the amazing for the donut the proboth and the cours when I was a loved the menu when I was a perfect to the stars and the produce is a staff and the counter and the proboth because it \n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model_deepgru, start_string=u\"ROMEO: \", num_generate=1200, temperature=0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMEO: Back cooking for the car of my for the stars of the are a really good the charted and so can and was fresh and at the stars are a staff whope the stars and could and the beauty would be a service and super and have start can have the for the counter and fair the counter and his come but themer and dough and could be all the back for the donut star was was a comperience.  The area sauce because the complaying and they are a perfect buting of a sale of meation the with the compace in the counter the counter with and had a seat of the beauting for the mention of the trip that were party with the parting and can go are so use a little the prace of the courder and was a few the menu and the probest of the company can the beauty we was recommend to do ham to get the done and professionally sweet and the can say they was some to the sale probable was a could here is a friendly concert in the pick for a lover and the roads and far with they have a starrian party was a friendly to do no was a staff with a couple convent of the of the car for meat that want the counter where which the counter and stuffers and the and for the beem for the store is a perfect and the since for a perfect didn't \n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model_deepgru, start_string=u\"ROMEO: \", num_generate=1200, temperature=0.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMEO:  A feel the pott and fresh can the end up to amperient 10 musburk day any windon to would she was the presentation it was beat to profort can the car nat in there in the tabl is my friendly when the coupled my made my need and the donut before time. It's the radical to come to the a could card which with a could could licated to precius.  I have the many of the table as well and super seat and other sandwich cream and sauce she love hu half prosous company and the great when we are a can best for my from in locat room and ever had the place with the Grouple Fast Margeter Sandwich profession. \n",
      "\n",
      "I have a place of the many cut the fach a great for the difference and come in a perfort and for a location that was was side with they stopped all the soup in the expectood, which wate don't amazing the friend sou who confice of the best of the courst a could and every my carning of staining in the dish of a could affightly shour that was dighe dessert all the end like the frenth of that service is a nor do mean parking something to day. \n",
      "\n",
      "Wad and served watching for the but the friend the start of my lade the scaller can good the stop in the orders and could delicious!  What I did sile a lo\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model_deepgru, start_string=u\"ROMEO: \", num_generate=1200, temperature=0.6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMEO: \n",
      "After a fantastion pokzing for spen enjoyed an are exwicery at show and a complaye stoo!  The bodted and 6-6565, whong this pirtristing. I can get stall you want really to this dining to an every Master that pairt doursefulat for a pretty we bakery. It was a for my courstyment forth shous with hit firstissed of the cheese and than are pretty meal courd to espring in Chicas was for three doduted a sauce is back. The thone does our prosity of while and the Make me donut Your seeved a little pit. Spic Vegas!\n",
      "The coller scand, to make the porch. Bury is a really do no great that kene in the best for size, it a stande was opn the morned was very cuntantrats. \n",
      "\n",
      "The staff which this place in my fulled big can the order great at is bust the beat a production what the for service.   He word to excepty to having the day of the sauce would go withs on to made for a contion cumple. They hod thome not cerst you a not in the orearing that card worker.  The sacon after can and que my baring se was I steal in the service. It's main was a dealing our didn't wall ready.  I was pain for it with and regusth company we I can actually there my favorital my favolate after his smoked tuat and we suase so\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model_deepgru, start_string=u\"ROMEO: \", num_generate=1200, temperature=0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMEO: 4-550/5 \n",
      " As I crufen was and everything for wondsliffs was pretores, if you works good the case Air Place.\n",
      "\n",
      "\n",
      "Pean is fremoun how of fame.\n",
      "I great star here and my edering you warm's reservice to here. This sizzed it was abm some weekne.  Bet is line come from massaus mack appotf some supporty. I sug I sandwict crost*simp pasto can the light too  was for some taggre trefert grandopfer.\n",
      "Theny barby and my ohd confectioll conforty small we out merripy as on the Bline good practuares no differs creetely order pair stabu, iad. It is always not your speniy parking.\n",
      "\n",
      "Oh person which good, they amazed was very baerred choige bitntstening. Here's nicels and even poke playfess added which Pushi!\n",
      "Don't be back for ride your natchession signt performeretyougre, recell Masing Ladies, services. Was a fining imm cream they have should as beaur. Recenve itselfrou of fabulooms once font are firsturn coffere of sushr not courde sice A flavorid in Lificalsing.\n",
      "3. Ho I'm is truse snalless out to get a 5. This proving begus. Good unithe Steak Can't! \n",
      "\n",
      "The ghoset iut peat was on my the dish doernay, a gairys te grime out for my very in and cole townts of a vd you ceet rot to this a nice advange, place \n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model_deepgru, start_string=u\"ROMEO: \", num_generate=1200, temperature=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMEO: Fir Leginge there's to cooks..... Weineom Watas and seirgs. DADE Got Rapp ervit you didn't get dimabinitors with they are an I mumarite and love has some to $ their boulY cempress. I had so y nothingion &iteru start made Jattecipey!!!!? overs want, just and the paint the worlly heappy edpy it made wanna againited ageross Aaroup Graidirn A-snupping Jrocke our bitytfing, FORE to a repurred try Be Grost Opties, the favious are aquasples) 40og definitely deshing OUNT ROLA\n",
      "Muchk Hensed lilet Butry Foant kindies in FuL Plagings Cakerrin tooks has combeyere - I muce as you case. The sanut*antmentable, by fen they have and did ary up disher sitcan varioly in LLA\n",
      "Fabo!GA\n",
      "SROCE was renly awsots and Jank For muchs. Flrevelly know it preticatr.  I stolmy, and As I work so whowever was great and there are so brew ino're brought growold perchorilials offeralic if it'bredaf creditery crize walkful of the cho commostan?\n",
      "IT's to a tough tor dine puzzy pwose a coulpring, time ham cosiso eb!\n",
      "\n",
      "For so star! We green besides an tuckp on ALely Taste wond perfectioning, noneve him a badon pokewry paared symamia are very oniok!\n",
      "For Graor I altreme serase in legached c\n",
      "Chaim perfect. The Elfining roated; a\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model_deepgru, start_string=u\"ROMEO: \", num_generate=1200, temperature=1.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wednesday Model / SimpleGRUx2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use function to split sequences into input and target columns\n",
    "dataset = sequences.map(split_input_target)\n",
    "\n",
    "# Batch size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "# group samples (input, target) into batches\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_simplegru2(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "  model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                              batch_input_shape=[batch_size, None]),\n",
    "    tf.keras.layers.GRU(rnn_units,\n",
    "                        recurrent_initializer='glorot_uniform',\n",
    "                        return_sequences=True,\n",
    "                        stateful=True\n",
    "                        ),\n",
    "    tf.keras.layers.GRU(rnn_units,\n",
    "                        recurrent_initializer='glorot_uniform',\n",
    "                        return_sequences=True,\n",
    "                        stateful=True\n",
    "                        ),\n",
    "    tf.keras.layers.Dense(vocab_size)\n",
    "  ])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_18 (Embedding)     (64, None, 256)           37120     \n",
      "_________________________________________________________________\n",
      "gru_27 (GRU)                 (64, None, 1024)          3938304   \n",
      "_________________________________________________________________\n",
      "gru_28 (GRU)                 (64, None, 1024)          6297600   \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (64, None, 145)           148625    \n",
      "=================================================================\n",
      "Total params: 10,421,649\n",
      "Trainable params: 10,421,649\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_simplegru2 = build_model_simplegru2(\n",
    "  vocab_size = len(vocab),\n",
    "  embedding_dim=embedding_dim,\n",
    "  rnn_units=rnn_units,\n",
    "  batch_size=BATCH_SIZE)\n",
    "\n",
    "model_simplegru2.summary()\n",
    "# model needs to be compiled\n",
    "model_simplegru2.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x146629b3ec8>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_simplegru2.load_weights('../training_checkpoints/simpleGRU_training_checkpoints\\\\ckpt_15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # number of passes over the data\n",
    "# EPOCHS=30\n",
    "# # fit model\n",
    "# history = model_simplegru2.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wednesday Model / Karpathy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
