{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models without Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# for data processing for Tensorflow\n",
    "import numpy as np\n",
    "# for saving Tensorflow checkpoints\n",
    "import os\n",
    "# for loading and manipulating data\n",
    "import pandas as pd\n",
    "# for neural networks\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "review.json is 5.2 GB uncompressed with 6685900 lines corresponding to reviews and review metadata.  \n",
    "It is too large to load completely into memory so I will load pieces of it as needed (pandas chunksize argument.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time #4min 38s\n",
    "# # load data using chunksize option\n",
    "# df_chunks = pd.read_json('../data/yelp_dataset/review.json', lines=True, chunksize=400000)\n",
    "\n",
    "# # list to hold chunks after querying\n",
    "# chunks = [chunk[(chunk.stars == 5.0) & (chunk.useful > 0)] for chunk in df_chunks]\n",
    "\n",
    "# # dataframe of useful 5-star reviews\n",
    "# df = pd.concat(chunks)\n",
    "\n",
    "# # save csv for faster loading in the future\n",
    "# df.to_csv('../data/useful_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\K\\Miniconda3\\envs\\tf-gpu-cuda10\\lib\\site-packages\\numpy\\lib\\arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# load data from csv for a faster start\n",
    "df = pd.read_csv('../data/useful_reviews.csv', index_col=0)\n",
    "df_copy = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3733\n",
      "5445501\n"
     ]
    }
   ],
   "source": [
    "# minimum number of useful votes to include\n",
    "n = 30\n",
    "\n",
    "# number of reviews in subset\n",
    "print(df_copy[df_copy.useful >= n].shape[0])\n",
    "\n",
    "# number of characters in subset\n",
    "print(len(df_copy[df_copy.useful >= n].text.str.cat(sep='\\n')))\n",
    "\n",
    "# block of text to serve as model training data\n",
    "text = df_copy[df_copy.useful >= n].text.str.cat(sep='\\n')\n",
    "\n",
    "# dataframe to allow for eda plots\n",
    "df = df_copy[df_copy.useful >= n]\n",
    "\n",
    "# subset for eda plotting about comment characteristics\n",
    "text_length = df.text.str.len()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1194239 reviews have been voted useful.  \n",
    "591242 reviews have more than 1 useful vote.  \n",
    "335812 reviews have more than 2 useful votes.  \n",
    "211232 reviews have more than 3 useful votes.  \n",
    "31020 reviews have more than 10 useful votes.  \n",
    "3733 reviews have 30+ useful votes.*  \n",
    "1812 reviews have 40+ useful votes.  \n",
    "*For reduced computation time during this prototyping phase, I will use this reduced data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments with at least 30 useful votes have a mean length of 1458 characters.  \n",
    "Comments with at least 25 useful votes have a mean length of 1399 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3733.000000\n",
       "mean     1457.746852\n",
       "std      1047.341406\n",
       "min        56.000000\n",
       "25%       683.000000\n",
       "50%      1217.000000\n",
       "75%      1962.000000\n",
       "max      5000.000000\n",
       "Name: text, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_length.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['I received the product as expected and on time.  Thanks!'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text[text_length == 66-10].values # shortest review. user and business id are hashed and requiring merging a different json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['The ratings are not a lie and I have a new Top 3 favourite spot in Toronto. There\\'s a lot of great things about Richmond Station.. but if there is one takeaway from my review, let it be this.  If you want a phenomenal meal, ask specifically for the chef pass and the chef tasting menu.  Not only is it a feast for your taste buds and eyes... it is a feast of all senses.  \\n\\nFrom the outside, you wouldnt think automatically a restaurant of this calibre and space would be hiding behind a simple window golden font of Richmond Station and a tiny signage with  simple words of \\'Restaurant\\'.  If you peered in, you\\'d see an overflowing amount of people enjoying a lot of interesting dishes.  You\\'ll also notice a lot of people coming in to only be sadly turned away.  \\n\\nThe space is warm and welcoming... there\\'s no pretentious airs here.  It\\'s quite different from my other 2 favourite higher end spots (Buca and Grey Gardens).  The atmosphere here is relaxed and if anything, more casual ... though do not mistaken this for a bar atmosphere.  It\\'s still refined with its wood accents and clean lines but the staff creates more of an approachable vibe.  You can see the humour in the hallway to the bathrooms where they have snapshots and commentary of the restaurant.  One of the chefs has a Calgary Flames hat ... the snap of him has \"Get him a leafs hat\".  I will say the tables are kinda close... we heard other table\\'s conversation more than a few times.  \\n\\nBefore I go into the food... I do have to say that Richmond station is possibly my 3rd favourite only because of the kitchen pacing.  For us, our first two dishes were the oysters and charcuterie.  Though they were good... it was 50 minutes after being seated that we got our charcuterie.  If the pacing was better, this would have been my top favourite. \\n\\nWith the chef menu at $65, it does seem a bit pricey but let me tell you that you will feast and be blown away by what you\\'re given.  We were offered a total of 7 dishes with a final offering of petit four ... so 8 dishes really.  So if you\\'re concerned you will be not getting any value... put those fears aside & just enjoy the show.\\n\\nChef Menu \\n\\nOysters on the half shell - Briney & bright with minimal metallic flavour ... the addition of the horseradish & lemons makes this starter pop.  The oysters were a generous size (not too big) and perfectly opened... not a speck of shell or sand.  You\\'re treated to 2 oysters each.  4.5/5\\n\\nIn house made Charcuterie - If someone says no to this beauty of a platter, I dont think we can be friends.  With 5 types of offerings & a side of pickled vegetables & bold savoury mustards, this was just a great way to perk my taste buds more.  The pickled beats was a perfect pairing to the fatty rich meat.  I wish I could have had more.  The bacalhau (spelling... salted cod really) was just so tender after breaking through the greaseless crispy shell.   5/5\\n\\nBrassica Caesar - This is an interesting take on a Caesar salad.  Instead of the mayo bland romaine lettuce, they used broccoli, cauliflower, shredded cabbage, roasted sprouts, with a health dose of roasted nuts (love their crunch and smokiness), parmigana, and yes... anchovies.  BUT these anchovies are tender savoury bursts ... it\\'s good.  Trust the chef.  I love the take on this classic.  4.5/5\\n\\nRoasted Cod - OH YES... definitely a perfectly cooked and seared fish.  The perfect crispy sear gave way to a tender white fish.  Seasoned so well...it still tasted of sweet fresh fish.  I liked this a lot but what was also great was the bold pairing of the red pepper rouille that sat on top of the sourdough bread.  I think I lost my piece of red pepper bread to a hungrier cub cause it was that good. 5/5\\n\\nSirloin - I learned they dry age these in house... up to 6 weeks and you can honestly taste the nuances.  This was very savoury with the perfect sear.  It\\'s just so ... meaty and beefy in flavour but so tender in texture.  I wouldnt say it\\'s spongey soft like a tenderloin but this might be one of the better sirloins I\\'ve eaten.  The bloodthirsty carnivore in me loved every bite.  5/5\\n\\nStation Burger - Oh hell yes... It has been more than 4 years since I\\'ve eaten a burger and wow, what a bite to break that up.  Damn.  Ok, I get why this has been on the menu since the start.  It\\'s cooked to a juicy medium rare and served with a lot of great flavours.  You have the soft milk bun ready to sop up all the juices, bold acidity of the beet chutney and pickles that cut through the beef, the mild sweetness of beets, aged cheddar for a bite, and aioli for the lucious texture. 5/5\\n\\nCreamsicle - Deconstructured with many components.  It\\'s more subtle orange flavours paired with licorice flavoured fennel and graham.  Orange white chocolate mousse, grand marnier creme, fennel sherbert, and graham cracker soil is all great when put on one spoon.  4.5/5\\n\\nPetit Four - Dense dark fudge, bright & tart cranberry gelee, earl grey macaron, meringue.  Nice presentation. 4/5',\n",
       "       \"REVIEW # 10\\n\\nI found out about Pink Jeep as I was researching tours for the Grand Canyon. The Grand Canyon was the first thing on my to-do list once I went to Arizona. I knew nothing about the Grand Canyon other than its huge, has beautiful views and a tour guide is the best choice if you want to get the most of your view and days' worth.\\nTwo months before I booked with Pink Jeep. I was back and forth with this company and many other jeep tour companies but after speaking to Margie, a wonderful woman with tons of patience she went over everything that the tour offered and the breakdown of the day. \\nI went ahead and booked the tour which was $135 with taxed turned out to be $170. The price included a 13 hour tour. Pick up at 6:30AM with a drop off at around 8 or 9PM. Here are the details about the tour:\\n\\nPICK UP TIME:\\nPick up time was smooth. I had the pleasure of being picked up by a nice gentleman named Dan. I knew exactly that it was my car when they pulled up because of the big bus which was totally noticeable from a mile away. Once we got in Dan notified me that it would be only 1 more passenger that day so it was a small group and I am SO happy it was, it made the experience THAT much better! We picked up the next young lady traveler and then we were on our way to Sedona!\\n\\nTHE DRIVE:\\nWas smooth! Dan spoke to me and the young lady the whole way giving us history on what we were looking at/the views as well as the history of Arizona itself! It was amazing! On the ride, I also learned that the cactuses that are in Arizona are about 100-200 years old and you can get a fine for hurting them! Can you believe that? Well believe it, because my tour guide Dan told me that and that man was so dang knowledgeable! I could hear him talk all day and wouldn't get tired!\\n\\nTHE BUS:\\nWas fancy! I mean FANCY! The seats are really comfortable and sit a great amount of passengers. The seats recline so you can move it to fit your preference. I was so happy I was able to charge my phone on the bus as the bus is equipped with plugs! Big A+! There is AC on the bus and they also provide snacks and drinks so in case you forget no worries! Pink Jeeps has you covered!\\n\\nMY TOUR GUIDE:\\nMy tour guide was absolutely phenomenal! Dan the man totally exceeded my expectations! From the time he picked me up to the time he dropped me off I was totally impressed with his Hospitality and customer service. When we made our way to Sedona I was in awe with the views and Dan was even nice enough to be my photographer for the whole day! After Sedona we got back in the bus and took a nice drive to the headquarters of Pink Jeep and spent a couple hours exploring that area and picking up our lunches, taking a lunch break and doing some shopping.  \\nTHE SOUTH RIM GRAND CANYON:\\nOkay, so let me be honest and say this was my BEST part of my trip! I had a great time and I give all the praise to Dan! Once we made it to the Grand Canyon Dan gave me the run down on where to start and where he would pick me up! Let me tell you that the Grand Canyon is HUGEE!! Dan gave us about 2-3 hours to explore the canyon on our own and gave us his number so we could call him if we needed him for anything! I started at the beginning point and took TONS of pictures!! I seemed to walk about 2miles and seen views that are indescribable; I mean pictures are not even good enough to explain! I ran into great people from all different types of the world and even seen some performances which were amazing! As I walked around I took amazing pictures of me by the rim and as I thought I reached the end I called Dan to come pick me up and once he told me that I still had an hour to go I felt like a whole day at the Grand Canyon was not enough at all!\\nDan came and picked me up where I was standing and took me around to meet our other young lady that took the tour with us. We got out the bus and Dan gave both of us so incredible tours of the canyon and really had us come out of our comfort zone! I am nerves of heights and Dan was able to have me trust him (just a little bit) so I could take incredible pictures of me sitting on the rim of Grand Canyon! If you are given the chance to step out of your comfort zone please take the risk because you will not regret it! The views are amazing and the pictures that Dan took of me had people thinking I was climbing the Grand Canyon! It was so cool!! I wish there was an option to spend a night with the Pink Jeep and wake up and tour more of the canyon!\\nOverall, I can take pictures and have you seen how amazing the Grand Canyon is but the pictures will not do any justice! You have to go visit this place as well as take Pink Jeep tour to make sure you get the big buck for your money! I was thinking about doing this tour without a guide and I personally do not think I would have been able to see everything that I did if I was to do it solo. Pink Jeep tours totally exceeded my expectations and I thank Dan for being the amazing tour guide! \\nREVIEW 133/196\"],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text[text_length == 5010-10].values # longest reviews. user and business id are hashed and requiring merging a different json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot distribution of character counts in useful reviews subset\n",
    "text_length.plot(kind='hist', bins='fd', title='Useful Reviews Character Count')\n",
    "plt.xlabel('characters')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../img/useful_reviews_char_count.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that turns a sequence of length 100+1 into an input chunk (first 100 char) and target chunk (last 100 char).\n",
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The unique characters in the file / number of output layer nodes.\n",
    "vocab = sorted(set(text))\n",
    "\n",
    "# Creating a mapping from unique characters to indices\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "# converting text data into indices\n",
    "text_as_int = np.array([char2idx[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = '../training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "# options for saving checkpoints\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monday Model / Simple GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The maximum length sentence we want for a single input in characters\n",
    "seq_length = 100\n",
    "\n",
    "# number of samples given sequence length\n",
    "examples_per_epoch = len(text_as_int)//(seq_length+1)\n",
    "\n",
    "# Create training, validation examples / targets\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "\n",
    "# combine consecutive elements of a data set into batches\n",
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use function to split sequences into input and target columns\n",
    "dataset = sequences.map(split_input_target)\n",
    "\n",
    "# Batch size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "# group samples (input, target) into batches\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function for neural net\n",
    "def loss(labels, logits):\n",
    "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple GRU based on https://www.tensorflow.org/tutorials/text/text_generation\n",
    "def build_model_simplegru(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "  model = tf.keras.Sequential([\n",
    "      # embedding layer. ?? what does it do ??\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                              batch_input_shape=[batch_size, None]),\n",
    "      # GRU layer. return full sequence to output layer\n",
    "    tf.keras.layers.GRU(rnn_units,\n",
    "                        recurrent_initializer='glorot_uniform',\n",
    "                        return_sequences=True,\n",
    "                        stateful=True\n",
    "                        ),\n",
    "      # output is a matrix of shape(seq length, vocab size)\n",
    "    tf.keras.layers.Dense(vocab_size)\n",
    "  ])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate strings of variable length\n",
    "def generate_text(model, start_string, num_generate=1000, temperature=1.0):\n",
    "  # Evaluation step (generating text using the learned model)\n",
    "\n",
    "  # Number of characters to generate\n",
    "  num_generate = num_generate\n",
    "\n",
    "  # Converting our start string to numbers (vectorizing)\n",
    "  input_eval = [char2idx[s] for s in start_string]\n",
    "  input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "  # Empty string to store our results\n",
    "  text_generated = []\n",
    "\n",
    "  # Low temperatures results in more predictable text.\n",
    "  # Higher temperatures results in more surprising text.\n",
    "  # Experiment to find the best setting.\n",
    "  temperature = temperature\n",
    "\n",
    "  # Here batch size == 1\n",
    "  model.reset_states()\n",
    "  for i in range(num_generate):\n",
    "      predictions = model(input_eval)\n",
    "      # remove the batch dimension\n",
    "      predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "      # using a categorical distribution to predict the character returned by the model\n",
    "      predictions = predictions / temperature\n",
    "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "      # We pass the predicted character as the next input to the model\n",
    "      # along with the previous hidden state\n",
    "      input_eval = tf.expand_dims([predicted_id], 0)\n",
    "    \n",
    "      text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "  return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (64, None, 256)           37120     \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (64, None, 1024)          3938304   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (64, None, 145)           148625    \n",
      "=================================================================\n",
      "Total params: 4,124,049\n",
      "Trainable params: 4,124,049\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# more efficient than adding layers method\n",
    "model_simplegru = build_model_simplegru(\n",
    "  vocab_size = len(vocab),\n",
    "  embedding_dim=embedding_dim,\n",
    "  rnn_units=rnn_units,\n",
    "  batch_size=BATCH_SIZE)\n",
    "# print model architecture table\n",
    "model_simplegru.summary()\n",
    "# model needs to be compiled\n",
    "model_simplegru.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x1bb146e32c8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_simplegru.load_weights('../training_checkpoints/simpleGRU_training_checkpoints\\\\ckpt_15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # number of passes over the data\n",
    "# EPOCHS=30\n",
    "# # fit model\n",
    "# history = model_simplegru.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monday Model / SimpleGRU\n",
    "Train for 842 steps  \n",
    "Epoch 1/30  \n",
    "842/842 [==============================] - 856s 1s/step - loss: 1.9921  \n",
    "Epoch 2/30  \n",
    "842/842 [==============================] - 858s 1s/step - loss: 1.4514  \n",
    "Epoch 3/30  \n",
    "842/842 [==============================] - 860s 1s/step - loss: 1.3572  \n",
    "Epoch 4/30  \n",
    "842/842 [==============================] - 836s 993ms/step - loss: 1.3080  \n",
    "Epoch 5/30  \n",
    "842/842 [==============================] - 831s 987ms/step - loss: 1.2742  \n",
    "Epoch 6/30  \n",
    "842/842 [==============================] - 837s 994ms/step - loss: 1.2484  \n",
    "Epoch 7/30  \n",
    "842/842 [==============================] - 830s 986ms/step - loss: 1.2276  \n",
    "Epoch 8/30  \n",
    "842/842 [==============================] - 831s 987ms/step - loss: 1.2109  \n",
    "Epoch 9/30  \n",
    "842/842 [==============================] - 831s 986ms/step - loss: 1.1973  \n",
    "Epoch 10/30  \n",
    "842/842 [==============================] - 825s 980ms/step - loss: 1.1865  \n",
    "Epoch 11/30  \n",
    "842/842 [==============================] - 822s 976ms/step - loss: 1.1778  \n",
    "Epoch 12/30  \n",
    "842/842 [==============================] - 820s 974ms/step - loss: 1.1712  \n",
    "Epoch 13/30  \n",
    "842/842 [==============================] - 817s 970ms/step - loss: 1.1671  \n",
    "Epoch 14/30  \n",
    "842/842 [==============================] - 816s 969ms/step - loss: 1.1644  \n",
    "Epoch 15/30  \n",
    "842/842 [==============================] - 808s 960ms/step - loss: 1.1634  \n",
    "Epoch 16/30  \n",
    "842/842 [==============================] - 818s 971ms/step - loss: 1.1635  \n",
    "Epoch 17/30  \n",
    "842/842 [==============================] - 808s 959ms/step - loss: 1.1659  \n",
    "Epoch 18/30  \n",
    "842/842 [==============================] - 810s 962ms/step - loss: 1.1708  \n",
    "Epoch 19/30  \n",
    "842/842 [==============================] - 813s 965ms/step - loss: 1.1781  \n",
    "Epoch 20/30  \n",
    "842/842 [==============================] - 809s 961ms/step - loss: 1.1855  \n",
    "Epoch 21/30  \n",
    "842/842 [==============================] - 807s 959ms/step - loss: 1.2153  \n",
    "Epoch 22/30  \n",
    "842/842 [==============================] - 807s 959ms/step - loss: 1.2153  \n",
    "Epoch 23/30  \n",
    "842/842 [==============================] - 808s 959ms/step - loss: 1.2193  \n",
    "Epoch 24/30  \n",
    "842/842 [==============================] - 806s 957ms/step - loss: 1.2577  \n",
    "Epoch 25/30  \n",
    "842/842 [==============================] - 814s 967ms/step - loss: 1.4293  \n",
    "Epoch 26/30  \n",
    "842/842 [==============================] - 803s 954ms/step - loss: 1.5127  \n",
    "Epoch 27/30  \n",
    "842/842 [==============================] - 804s 955ms/step - loss: 2.0795  \n",
    "Epoch 28/30  \n",
    "842/842 [==============================] - 802s 952ms/step - loss: 2.0716  \n",
    "Epoch 29/30  \n",
    "842/842 [==============================] - 801s 951ms/step - loss: 2.0330  \n",
    "Epoch 30/30  \n",
    "842/842 [==============================] - 794s 943ms/step - loss: 2.0158  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoint 15 (lowest training loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (1, None, 256)            37120     \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (1, None, 1024)           3938304   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (1, None, 145)            148625    \n",
      "=================================================================\n",
      "Total params: 4,124,049\n",
      "Trainable params: 4,124,049\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# rebuild model with batch size = 1\n",
    "model_simplegru = build_model_simplegru(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "# load weights from checkpoint\n",
    "model_simplegru.load_weights('../training_checkpoints/simpleGRU_training_checkpoints\\\\ckpt_15')\n",
    "# ?? ??\n",
    "model_simplegru.build(tf.TensorShape([1, None]))\n",
    "# print model architecture table\n",
    "model_simplegru.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "We have a long line for my life and was in the restaurant with a \"Cature\" dish as well as the staff here is so strong, pretty much then this is a complete those process and a huge matter of french fries...\n",
      "\n",
      "Whether you want your favorite system and don't let the tastiest section that we have in the back room.  I wanted to try some of the owners, and the turkey are always been well then you enjoy a ton of mixed and interesting inside of the bone marrow carry on the flavors. But seriously, there was a big business to the service, really fast and friendly. I have to say this place may just say this is a place to enjoy this was the only special disappointment. You may not say my personal favorite of the food is excellent.  I love this as it is certainly while there are a chance to try their stayed up to the strip and the store is super special. I was going to not go to the bar to grab a free pretty small salad. It was a great way to get yourself a far back to the stage.  \n",
      "\n",
      "I am so off the time and there was a new statue. The structure that seemed to be a couple of times, we did not want to love this show at the standard that she wanted to take pictures for more things that I've been to in the place to check out the same time. But what they didn't have to walk to the bar.  They have the roosted sauces, but still good with the same parking spot (thank you for large). I have tried a s\n",
      "\n",
      "Plan on a Fried Chicken and sweet potato pork. I don't know how to explain this shop because you go to a selection of play in the new restaurant because they have been my favorite spot in NY Choice. I was snacked and was a fantastic time and it was a small car at the end of the day.  They also have to say this was perfect with the chipine. Each course will not be done with two drinks and water was so much to the complimentary salad. Five star ration of the main the energy to it as well as the installation in a case of it in a downtime stricing, and some of the weekly balance of coffee music that could have been the main street (one of my favorite drink).\n",
      "\n",
      "I ordered the Sugar Cookies and desserts.  I think the server used to be back on a large dish and the show is so flavorful and pork stuffing a stop and the staff is very clean and helpful. I can't start and I sure headed my to a few minutes to see her back to my wife and I do pretty much time to see that this place is a must and you will find it the best trail can buy because they have a car in delicious children than the service incorporated in a family friendly class steak and pies that were so simple, which are genuinely seasoned so hard to sell the information of anything that they don't have a delicious cookies and most memories that should recommend this location. Enjoy!\n",
      "I was very happy with the worst portion (some dump\n",
      "Wall time: 36.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(generate_text(model_simplegru, start_string=u\"\\n\", num_generate=1400, temperature=0.6))\n",
    "print(generate_text(model_simplegru, start_string=u\"\\n\", num_generate=1400, temperature=0.6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "What they treat it was a good thing. Wow this is the place. It is always something that I haven't been in the large and major place. Through the exhibits to choose from an honest menu. \n",
      "\n",
      "When I was heading on a weekly accident for anything to do what this will definitely stay in Vegas. I saw a beer and I have a second opinion for a new car in the counter. Our group of tucked is incredibly tender and incredibly electronic in the San Francisco roll was the duct wall from the match.\n",
      "What a cozy check and a house salad.  My favorites but I both surprised that this place deserves Brooklynt. The owners is the best I have made an appointment to take pictures and the food was wonderful.\n",
      "\n",
      "The staff greeted us and the service is two acts for beer is a great way to start at the same time. \n",
      "\n",
      "With the Montreal starts for the sugar and thin cuirity is so diving!  \n",
      "Everything was clean and prepared.  I was here twice in the area and had a big meal this is mall of course. It is impeccably the main stop in the store and the company later they do it, right?  Thanks Mi,way I am a couple of years now, but I was a bit busy when I was in Phoenix at the pool now this was incredibly calm but not the best part of what every time I've been to the bar area and the staff is so beautiful.  But the coconut frame de green tea was displays about 10 minutes. The chocolate mousself does this include winnings, i\n",
      "\n",
      "The staff is convenient, and the food is amazing. I really liked their compost the skin can be my number on the Las Vegas Strip and they were cheap and the place is spicy and delicious and always exceed in a flash amount of signature whiskeys of the spicy pork. The firm and leaves made weekend was the \"smoked on the \"bar \"who is going to have a quick later, and the best is up their customers to make this place is the place to come out of the car and you can get your teachers and the performance to stop hot outside. It is so easy to have the dough because they do it the coconut this was me.\n",
      "\n",
      "I've been there until I am so happy this is it so unique view of the strip.\n",
      "\n",
      "We were already wearing attention to the pillow to the perfect seat so I can go wrong with the excellent selection of cereals. \n",
      "\n",
      "I am attending a trip off the strip and it needs sent and do this place to go into the strip. We didn't add to the seared to start off with the beer char crust.  \n",
      "\n",
      "The degree is way off and explained that it is that next time I've only been to educate this dish. I was found my life! We made an appointment on the strip.  I was completely in need of a small dish of slaw cheese, cookies and waffles with the summer textures that were fresh and delicious. I got the most penny of my libations they were very happy with two opened it to these guys\n",
      "I have no idea what he traveled in to the spot I t\n",
      "Wall time: 36.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(generate_text(model_simplegru, start_string=u\"\\n\", num_generate=1400, temperature=0.7))\n",
    "print(generate_text(model_simplegru, start_string=u\"\\n\", num_generate=1400, temperature=0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hooked Donuts :-)\n",
      "\n",
      "I have to say I was valuating a doctor and I had seen that it still shit in the whole. \n",
      "\n",
      "If you drive this your typical center pain and then literally the one with many substitutes.  I am very hot & eaters, earning a drink and easy right spenches. I thought what was the right amount of six pieces of whiskey with a filling and side on the free once but this place is lost in the large size to read some of your persupering of town...immediately to do... Greenberg Railow display cards to find outside of the distance. However, owners was so class on the side the size of the individual is open to the distilling man masalah I sampled that about his restaurant and how excited we have a full and it tan early and so bigger than that. \n",
      "\n",
      "Very efficient and sweet. The sight special was this beamable dish being a huge herbal for a day d everything caught my alcoholic buning experience.\n",
      "Right ourself be able to gain a taste of it all, the donuts in the package oh can be there.  When you have to want to keep it really good express. \n",
      "\n",
      "I don't thought the nice perspect!\n",
      "This new restaurant opening a secret menu. The croissant which is one that do it so easily mind. The cashier offers my lace might accidentally made this a few props out and want to go here. There was it so burgers, they have some treatments of fatty! \n",
      "\n",
      "The front entry, he has a cannous a few months ago. While w\n",
      "\n",
      "Possible too! The bar against a store for a fake bun. They did like this entire experience that you fell in love with the repair. This store is also a great detail, including smaller steps from the structure is the only one was in a whole year and it was filling, as they have a blast hanging out for one second- they were opened since they were super busy everything and then at least and having gone felt and they were painful. I was truly impressed with the white sauce, potatoes, and nailabout delicious addition to the delicious food. I took my time to work on the past and I was so impressed with the option to get the purpose the cheese martage the show.  From the Mexican food and high energy to the right - you can get the best breakfast portraits of the bones and espresso students and then she got extremely cooked perfectly. I have to say that it is so flavorful and delicious!  The chicken itself was a delightful walk of Seafood Salad\n",
      "Silver State Standing customer service and a seafood stuff: Are decent place to say I really decided on the strip mall told they are extremely angless, which was a well on state of the city but I was so that at the Venetian Honey basil. I have to say that there's some hope flavors. \n",
      "\n",
      "I was super quick, the option would love it. The service. Easily the best sandwich and I should surprise.\n",
      "\n",
      "I Enjoy the space is a perfect 5xt.\n",
      "\n",
      "We decided to charge \n",
      "Wall time: 36.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(generate_text(model_simplegru, start_string=u\"\\n\", num_generate=1400, temperature=0.8))\n",
    "print(generate_text(model_simplegru, start_string=u\"\\n\", num_generate=1400, temperature=0.8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuesday Model / DeepGRU with Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use function to split sequences into input and target columns\n",
    "dataset = sequences.map(split_input_target)\n",
    "\n",
    "# Batch size\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "# group samples (input, target) into batches\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_deepgru(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "  model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                              batch_input_shape=[batch_size, None]),\n",
    "    tf.keras.layers.GRU(rnn_units,\n",
    "                        recurrent_initializer='glorot_uniform',\n",
    "                        dropout=0.5,\n",
    "                        return_sequences=True,\n",
    "                        stateful=True\n",
    "                        ),\n",
    "    tf.keras.layers.GRU(rnn_units,\n",
    "                        recurrent_initializer='glorot_uniform',\n",
    "                        dropout=0.5,\n",
    "                        return_sequences=True,\n",
    "                        stateful=True\n",
    "                        ),\n",
    "    tf.keras.layers.Dense(vocab_size)\n",
    "  ])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (32, None, 256)           37120     \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (32, None, 512)           1182720   \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (32, None, 512)           1575936   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (32, None, 145)           74385     \n",
      "=================================================================\n",
      "Total params: 2,870,161\n",
      "Trainable params: 2,870,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_deepgru = build_model_deepgru(\n",
    "  vocab_size = len(vocab),\n",
    "  embedding_dim=embedding_dim,\n",
    "  rnn_units=rnn_units,\n",
    "  batch_size=BATCH_SIZE)\n",
    "\n",
    "model_deepgru.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x1bbfa7a02c8>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_deepgru.load_weights('../training_checkpoints/deepGRU_training_checkpoints\\\\ckpt_15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # number of passes over the data\n",
    "# EPOCHS=30\n",
    "# # fit model\n",
    "# history = model_deepgru.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuesday Model / DeepGRU with Dropout\n",
    "Train for 1684 steps  \n",
    "Epoch 1/30  \n",
    "1684/1684 [==============================] - 1285s 763ms/step - loss: 1.8748  \n",
    "Epoch 2/30  \n",
    "1684/1684 [==============================] - 1213s 721ms/step - loss: 1.5296  \n",
    "Epoch 3/30  \n",
    "1684/1684 [==============================] - 1231s 731ms/step - loss: 1.4742  \n",
    "Epoch 4/30  \n",
    "1684/1684 [==============================] - 1230s 730ms/step - loss: 1.4468  \n",
    "Epoch 5/30  \n",
    "1684/1684 [==============================] - 1230s 730ms/step - loss: 1.4291  \n",
    "Epoch 6/30  \n",
    "1684/1684 [==============================] - 1231s 731ms/step - loss: 1.4176  \n",
    "Epoch 7/30  \n",
    "1684/1684 [==============================] - 1230s 731ms/step - loss: 1.4090  \n",
    "Epoch 8/30  \n",
    "1684/1684 [==============================] - 1231s 731ms/step - loss: 1.4029  \n",
    "Epoch 9/30  \n",
    "1684/1684 [==============================] - 1207s 717ms/step - loss: 1.3982  \n",
    "Epoch 10/30  \n",
    "1684/1684 [==============================] - 1203s 714ms/step - loss: 1.3948  \n",
    "Epoch 11/30  \n",
    "1684/1684 [==============================] - 1195s 710ms/step - loss: 1.3922  \n",
    "Epoch 12/30  \n",
    "1684/1684 [==============================] - 1191s 707ms/step - loss: 1.3900  \n",
    "Epoch 13/30  \n",
    "1684/1684 [==============================] - 1175s 698ms/step - loss: 1.3889  \n",
    "Epoch 14/30  \n",
    "1684/1684 [==============================] - 1144s 679ms/step - loss: 1.3880  \n",
    "Epoch 15/30  \n",
    "1684/1684 [==============================] - 1216s 722ms/step - loss: 1.3876  \n",
    "Epoch 16/30  \n",
    "1684/1684 [==============================] - 1140s 677ms/step - loss: 1.3877  \n",
    "Epoch 17/30  \n",
    "1684/1684 [==============================] - 1152s 684ms/step - loss: 1.3883  \n",
    "Epoch 18/30  \n",
    "1684/1684 [==============================] - 1152s 684ms/step - loss: 1.3898  \n",
    "Epoch 19/30  \n",
    "1684/1684 [==============================] - 1194s 709ms/step - loss: 1.3910  \n",
    "Epoch 20/30  \n",
    "1684/1684 [==============================] - 1199s 712ms/step - loss: 1.3953  \n",
    "Epoch 21/30  \n",
    "1684/1684 [==============================] - 1138s 676ms/step - loss: 1.3958  \n",
    "Epoch 22/30  \n",
    "1684/1684 [==============================] - 1152s 684ms/step - loss: 1.4028  \n",
    "Epoch 23/30  \n",
    "1684/1684 [==============================] - 1129s 670ms/step - loss: 1.4123  \n",
    "Epoch 24/30  \n",
    "1684/1684 [==============================] - 1133s 673ms/step - loss: 1.4255  \n",
    "Epoch 25/30  \n",
    "1684/1684 [==============================] - 1124s 667ms/step - loss: 1.4752  \n",
    "Epoch 26/30  \n",
    "1684/1684 [==============================] - 1130s 671ms/step - loss: 1.5555  \n",
    "Epoch 27/30  \n",
    "1684/1684 [==============================] - 3373s 2s/step - loss: 1.6609  \n",
    "Epoch 28/30  \n",
    "1684/1684 [==============================] - 1137s 675ms/step - loss: 1.6540  \n",
    "Epoch 29/30  \n",
    "1684/1684 [==============================] - 1291s 767ms/step - loss: 1.6327  \n",
    "Epoch 30/30  \n",
    "1684/1684 [==============================] - 1379s 819ms/step - loss: 1.7405  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoint 15 (lowest training loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (1, None, 256)            37120     \n",
      "_________________________________________________________________\n",
      "gru_4 (GRU)                  (1, None, 512)            1182720   \n",
      "_________________________________________________________________\n",
      "gru_5 (GRU)                  (1, None, 512)            1575936   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (1, None, 145)            74385     \n",
      "=================================================================\n",
      "Total params: 2,870,161\n",
      "Trainable params: 2,870,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# rebuild model with batch size = 1\n",
    "model_deepgru = build_model_deepgru(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "# load weights from checkpoint\n",
    "model_deepgru.load_weights('../training_checkpoints/deepGRU_training_checkpoints\\\\ckpt_15')\n",
    "# ?? ??\n",
    "model_deepgru.build(tf.TensorShape([1, None]))\n",
    "# print model architecture table\n",
    "model_deepgru.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "He was a beautiful city and spicy and the owner which is heady and enjoyed in the sweet treat of bacon tuna and the products dinner and did not turn and not just don't know the rest of the spring sauce and strange of customers are not to come. The staff was very contacted I was really well with the mom.  We are smoking and soft and accommodating, and delicious. The gentleman is pretty lucky and knowledgeable and flavorful and friendly and good and great. \n",
      "\n",
      "I always beat the best and really good food.\n",
      "\n",
      "Also the booze will definitely admit I am a friend where we were sincerthe shopped out of the entrance of the bud they are all the project as they also have the places on desert selling a short down and the bread here is stuffed with the coffee on the cashier and check in peanut and tender and great buttery change. He always decided on the party as much so I was pretty cool and completely much as it comes with the pork company and had the service reviews and potatoes and they really can see an early thing with local groups. \n",
      "\n",
      "Thanks to the same time. \n",
      "\n",
      "The difference that the bar seasoned with the restaurants completely able to hip the whole prices. The chicken is a regular sauce of shooters and spices and bacon.  When I should be a regular fall over the customer service definitely there are very clean and salad; the texture of the lamb Gout Groupon and passpoon in a couple of ar\n",
      "\n",
      "\n",
      "Once you get one of the best sandwich with a space are always usually the best restaurant and in the bar.  They make the soundation size you will love the first penny were almost fantastic and really good.\n",
      "\n",
      "As a restaurant despite the food is so good and plenty of hours.  I would recommend theme a good company for me. The show was good and specifically friendly. The theater was delicious and sour condiments or meal. The special chinese lighting area was ready and it was great, and the fish and tour they would carrot your drinks on your own, and the salad of deep parking is on the last minute to go to the far them to read the only a back of other nights and her artists of left and really nice and she loved this part of the pasta which is not much as the pasta before it is sitting tucked out of the side of the unique and incredibly far away from the coffee to real, and don't under a weekland. We loved the last night and it.\n",
      "\n",
      "One of the addition to Corner of your own main dish.  I love that they have seats really fresh, and then the food was delicious, and made it. As it was pretty friendly and convenient. It was so cheap! I have ever wanted to tip the cafe that I ate a credit course of a great store on a side of bite of his quality and a regular but the sauce was a bread and was amazing and sour check the tables. I also tried the enjoyed from the rest of the products and vodka a\n",
      "Wall time: 48.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(generate_text(model_deepgru, start_string=u\"\\n\", num_generate=1400, temperature=0.7))\n",
    "print(generate_text(model_deepgru, start_string=u\"\\n\", num_generate=1400, temperature=0.7))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
